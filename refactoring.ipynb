{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict, OrderedDict\n",
    "\n",
    "class XaiHook(nn.Module):\n",
    "    def __init__(self, module):\n",
    "        super(XaiHook, self).__init__()\n",
    "        \"\"\"\n",
    "        Hook Handler Module\n",
    "        \n",
    "        supported register `module` hooks\n",
    "        - Activations\n",
    "        - Linear\n",
    "        - Convd\n",
    "        \n",
    "        like RNN have to use `register_hook` to `torch.nn.Parameter` directly\n",
    "        \n",
    "        * Ref: https://pytorch.org/docs/master/nn.html#torch.nn.Module.register_backward_hook\n",
    "        [Warnings]\n",
    "        The current implementation will not have the presented behavior \n",
    "        for complex Module that perform many operations. In some failure cases, \n",
    "        `grad_input` and `grad_output` will only contain the gradients for a subset\n",
    "        of the inputs and outputs. For such `Module`, you should use \n",
    "        `torch.Tensor.register_hook()` directly on a specific input or \n",
    "        output to get the required gradients.\n",
    "        \n",
    "        \"\"\"\n",
    "        self.module = module\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        self.module.zero_grad()\n",
    "\n",
    "    def register_hook(self, backward=False, hook_fn=None):\n",
    "        \"\"\"\n",
    "        defalut hook_function is save (module, input, output) to (m, i, o)\n",
    "        if you want to use hook function, change `hook_function` \n",
    "        if `hook_function` returns `None` then the original input or output \n",
    "        will be flow into next / previous layer, but you can return a modifed\n",
    "        output/gradient to change the original output/gradient.\n",
    "        for a Conv2d layer example\n",
    "        - forward: a `Tensor` type output\n",
    "        - backward: (gradient_input, weight, bias)\n",
    "        \n",
    "        \"\"\"\n",
    "        def default_hook_fn(m, i, o):\n",
    "            \"\"\"\n",
    "            forward\n",
    "             - m: module class\n",
    "             - i: forward input from previous layer\n",
    "             - o: forward output to next layer\n",
    "            backward\n",
    "             - m: module class\n",
    "             - i: gradient input to next layer (backward out)\n",
    "             - o: gradient output from previous layer (backward in)\n",
    "\n",
    "            args:\n",
    "             * i, o: tuple type\n",
    "            \"\"\"\n",
    "            self.m = m\n",
    "            self.i = i\n",
    "            self.o = o\n",
    "            \n",
    "        if hook_fn is None:\n",
    "            self.hook_fn = default_hook_fn\n",
    "        else:\n",
    "            self.hook_fn = hook_fn\n",
    "        if not backward:\n",
    "            self.hook = self.module.register_forward_hook(self.hook_fn)\n",
    "        else:\n",
    "            self.hook = self.module.register_backward_hook(self.hook_fn)\n",
    "            \n",
    "    def close(self):\n",
    "        self.hook.remove()\n",
    "\n",
    "\n",
    "class XaiBase(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XaiBase, self).__init__()\n",
    "        \"\"\"\n",
    "        - need to define XaiHook class to use\n",
    "        - defalut hook_function is save (module, input, output) to (m, i, o)\n",
    "          if you want to use hook function, change `hook_function` \n",
    "        \"\"\"\n",
    "        self._reset_maps()\n",
    "    \n",
    "    def _reset_maps(self):\n",
    "        self.maps = OrderedDict()\n",
    "        \n",
    "    def _save_maps(self, layer_name, x):\n",
    "        self.maps[layer_name] = x    \n",
    "        \n",
    "    def _register(self, hooks, backward=False, hook_fn=None):\n",
    "        \"\"\"\n",
    "        - need to define XaiHook class to use\n",
    "        - defalut hook_function is save (module, input, output) to (m, i, o)\n",
    "          if you want to use hook function, change `hook_function` \n",
    "        \"\"\"\n",
    "        if not isinstance(hooks, list):\n",
    "            hooks = [hooks]\n",
    "        for hook in hooks:\n",
    "            hook.register_hook(backward=backward, hook_fn=hook_fn)\n",
    "    \n",
    "    def _register_forward(self, hooks, hook_fn=None):\n",
    "        self._register(hooks, backward=False, hook_fn=hook_fn)\n",
    "        \n",
    "    def _register_backward(self, hooks, hook_fn=None):\n",
    "        self._register(hooks, backward=True, hook_fn=hook_fn)\n",
    "    \n",
    "    def _reset_hooks(self, hooks):\n",
    "        if not isinstance(hooks, list):\n",
    "            hooks = [hooks]\n",
    "        for hook in hooks:\n",
    "            hook.close()\n",
    "\n",
    "    def _return_indices(self, layers, on=True):\n",
    "        \"\"\"\n",
    "        support for cnn layer which have `nn.MaxPool2d`,\n",
    "        you can turn on/off pooling indices.\n",
    "        please define a forward function to use it in your model\n",
    "        '''\n",
    "        # in your model\n",
    "        def forward_switch(self, x):\n",
    "            switches = OrderedDict()\n",
    "            self.return_indices(on=True)\n",
    "            for idx, layer in enumerate(self.convs):\n",
    "                if isinstance(layer, nn.MaxPool2d):\n",
    "                    x, indices = layer(x)\n",
    "                    switches[idx] = indices\n",
    "                else:\n",
    "                    x = layer(x)\n",
    "            self.return_indices(on=False)\n",
    "            return x, switches\n",
    "        '''\n",
    "        \"\"\"\n",
    "        if on:\n",
    "            for layer in layers:\n",
    "                if isinstance(layer, nn.MaxPool2d):\n",
    "                    layer.return_indices = True\n",
    "        else:\n",
    "            for layer in layers:\n",
    "                if isinstance(layer, nn.MaxPool2d):\n",
    "                    layer.return_indices = False  \n",
    "                    \n",
    "                    \n",
    "class XaiModel(XaiBase):\n",
    "    def __init__(self, model):\n",
    "        super(XaiModel, self).__init__()\n",
    "        self.model = deepcopy(model)\n",
    "        self.model.cpu()\n",
    "        self.model.eval()\n",
    "        \n",
    "    def _one_hot(self, targets, module_name):\n",
    "        \"\"\"\n",
    "        one hot vectorize the target tensor for classification purpose.\n",
    "        the `module` with respect to `module_name` must have `out_features` attribution.\n",
    "        args:\n",
    "        - targets: torch.LongTensor, target classes that have size of mini-batch\n",
    "        - module_name: str, feature name for Fully-Connected Network or any Task-specific Network\n",
    "        return:\n",
    "        - one hot vector of targets\n",
    "        \"\"\"\n",
    "        assert isinstance(targets, torch.LongTensor), \"`targets` must be `torch.LongTensor` type\"\n",
    "        assert isinstance(module_name, str), \"`module_name` must be `str` type\"\n",
    "        modules = self.model._modules[module_name]\n",
    "        if isinstance(modules, nn.Sequential):\n",
    "            last_layer = modules[-1]\n",
    "        else:\n",
    "            last_layer = modules\n",
    "        try:\n",
    "            last_layer.out_features \n",
    "        except AttributeError as e:\n",
    "            is_linear = isinstance(last_layer, nn.Linear)\n",
    "            print(f\"last layer of module `{module_name}` doesn't have `out_features` attribute\")\n",
    "            print()\n",
    "            if not is_linear:\n",
    "                print(f\"type of the last layer is `{type(last_layer)}`\")\n",
    "                print(\"the last layer is not `torch.nn.linear.Linear` class\")\n",
    "                print(\"create `.out_featrues` attribution in the custom module\")\n",
    "                \n",
    "        target_size = last_layer.out_features\n",
    "        B = targets.size(0)\n",
    "        one_hot = torch.zeros((B, target_size))\n",
    "        one_hot.scatter_(1, targets.unsqueeze(1), 1.0)\n",
    "        return one_hot.to(targets.device)\n",
    "    \n",
    "    def _find_target_layer_idx(self, module_name, layer_names):\n",
    "        assert isinstance(layer_names, list) or isinstance(layer_names, tuple), \"use list for `layer_names`\"\n",
    "        layer_names = [l.lower() for l in layer_names]\n",
    "        idxes = defaultdict(list)\n",
    "        modules = self.model._modules[module_name]\n",
    "        assert isinstance(modules, nn.Sequential), \"use this function for `nn.Sequential` type modules\"\n",
    "        for idx, layer in modules.named_children():\n",
    "            l_name = type(layer).__name__.lower()\n",
    "            if l_name in layer_names:\n",
    "                idxes[l_name].append(int(idx))\n",
    "\n",
    "        return idxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelAttention(nn.Module):\n",
    "    \"\"\"Channel Attention Module\"\"\"\n",
    "    def __init__(self, C, ratio):\n",
    "        \"\"\"\n",
    "        Method in [arXiv:1807.06521]\n",
    "        args:\n",
    "         - C: channel of input features\n",
    "         - H: height of input features\n",
    "         - W: width of input features\n",
    "         - hid_size: hidden size of shallow network\n",
    "         - ratio: reduction ratio\n",
    "        \"\"\"\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        assert isinstance(2*C // ratio, int), \"`2*C // ratio` must be int \"\n",
    "        self.maxpool = nn.AdaptiveMaxPool2d((1, 1))\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.shallow_net = nn.Sequential(\n",
    "            nn.Linear(2*C, 2*C // ratio),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2*C // ratio, 2*C),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # (B, C, H, W) > (B, 2*C, 1, 1)\n",
    "        x = torch.cat([self.maxpool(x), self.avgpool(x)], dim=1)\n",
    "        # (B, 2*C) > (B, 2*C//2) > (B, 2*C)\n",
    "        x = self.shallow_net(x.squeeze(-1).squeeze(-1))\n",
    "        # (B, C), (B, C)\n",
    "        x_max, x_avg = torch.chunk(x, 2, dim=1)\n",
    "        # not using softmax in paper: something like gate function\n",
    "        x = torch.sigmoid(x_max + x_avg)\n",
    "        return x.unsqueeze(-1).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialAttention(nn.Module):\n",
    "    \"\"\"Spatial Attention Module\"\"\"\n",
    "    def __init__(self, H, W, K_H=7, K_W=7, S_H=1, S_W=1):\n",
    "        \"\"\"\n",
    "        Method in [arXiv:1807.06521]\n",
    "        args:\n",
    "         - H: height of input features\n",
    "         - W: width of input features\n",
    "         - K_H: height of kernel size\n",
    "         - K_W: width of kernel size\n",
    "         - S_H: stride height of conv layer\n",
    "         - S_W: stride width of conv layer\n",
    "        \"\"\"\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        P_H = self.cal_padding_size(H, K_H, S_H)\n",
    "        P_W = self.cal_padding_size(W, K_W, S_W)\n",
    "        kernel_size = (K_H, K_W)\n",
    "        stride = (S_H, S_W)\n",
    "        padding = (P_H, P_W)\n",
    "        # same padding conv layer\n",
    "        self.conv_layer = nn.Conv2d(2, 1, kernel_size, stride, padding)\n",
    "    \n",
    "    def cal_padding_size(self, x, K, S):\n",
    "        return int((S * (x-1) + K - x) / 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # (B, C, H, W) > (B, 1, H, W)\n",
    "        x_max, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x_avg = torch.mean(x, dim=1, keepdim=True)\n",
    "        # (B, 2, H, W)\n",
    "        x = torch.cat([x_max, x_avg], dim=1)\n",
    "        # (B, 2, H, W) > (B, 1, H, W)\n",
    "        x = self.conv_layer(x)\n",
    "        # return gated features\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBAM(nn.Module):\n",
    "    \"\"\"Convolution Block Attention Module\"\"\"\n",
    "    def __init__(self, C, H, W, ratio, K_H=7, K_W=7, S_H=1, S_W=1):\n",
    "        \"\"\"\n",
    "        Method in [arXiv:1807.06521]\n",
    "        args:\n",
    "         - C: channel of input features\n",
    "         - H: height of input features\n",
    "         - W: width of input features\n",
    "         - ratio: reduction ratio\n",
    "         - K_H: height of kernel size\n",
    "         - K_W: width of kernel size\n",
    "         - S_H: stride height of conv layer\n",
    "         - S_W: stride width of conv layer\n",
    "         \n",
    "        return:\n",
    "         - attentioned features, size = (B, C, H, W)\n",
    "        \"\"\"\n",
    "        super(CBAM, self).__init__()\n",
    "        self.channel_attn = ChannelAttention(C, ratio)\n",
    "        self.spatial_attn = SpatialAttention(H, W, K_H, K_W, S_H, S_W)\n",
    "        \n",
    "    def forward(self, x, return_attn=False):\n",
    "        \"\"\"\n",
    "        return: attentioned features, size = (B, C, H, W)\n",
    "        \"\"\"\n",
    "        out = x\n",
    "        c_attn = self.channel_attn(out)\n",
    "        out = c_attn * out\n",
    "        s_attn = self.spatial_attn(out)\n",
    "        out = s_attn * out\n",
    "        if return_attn:\n",
    "            return out, (c_attn, s_attn)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "\n",
    "class CnnWithCBAM(XaiBase):\n",
    "    def __init__(self):\n",
    "        super(CnnWithCBAM, self).__init__()\n",
    "\n",
    "        self.convs = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 5),  # (B, 1, 28, 28) > (B, 32, 24, 24)\n",
    "            CBAM(32, 24, 24, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # (B, 32, 24, 24) > (B, 32, 12, 12)\n",
    "            nn.Conv2d(32, 64, 3),  # (B, 32, 12, 12) > (B, 64, 10, 10)\n",
    "            CBAM(64, 10, 10, 16),\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(2),  # (B, 64, 10, 10) > (B, 64, 5, 5)\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64*5*5, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):        \n",
    "        x = self.convs(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    def forward_map(self, x):\n",
    "        self._reset_maps()\n",
    "        for i, layer in enumerate(self.convs):\n",
    "            layer_name = type(layer).__name__.lower()\n",
    "            if layer_name == \"cbam\":\n",
    "                x, attns = layer(x, return_attn=True)\n",
    "                self._save_maps(f\"{i}\"+layer_name, attns)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cnn(XaiBase):\n",
    "    def __init__(self):\n",
    "        super(Cnn, self).__init__()\n",
    "\n",
    "        self.convs = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 5),  # (B, 1, 28, 28) > (B, 32, 24, 24)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # (B, 32, 24, 24) > (B, 32, 12, 12)\n",
    "            nn.Conv2d(32, 64, 3),  # (B, 32, 12, 12) > (B, 64, 10, 10)\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(2),  # (B, 64, 10, 10) > (B, 64, 5, 5)\n",
    "            nn.Conv2d(64, 128, 2),  # (B, 128, 5, 5) > (B, 128, 4, 4)\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(2),  # (B, 128, 4, 4) > (B, 128, 2, 2)\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128*2*2, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):        \n",
    "        x = self.convs(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    def forward_map(self, x):\n",
    "        self._reset_maps()\n",
    "        for i, layer in enumerate(self.convs):\n",
    "            layer_name = type(layer).__name__.lower()\n",
    "            if layer_name == \"relu\":\n",
    "                x, attns = layer(x, return_attn=True)\n",
    "                self._save_maps(f\"{i}\"+layer_name, attns)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CnnWithCBAM()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class GradCAM(XaiModel):\n",
    "    \"\"\"GradCAM\"\"\"\n",
    "    def __init__(self, model, norm_mode=1):\n",
    "        \"\"\"\n",
    "        norm mode\n",
    "        - 1 ( 0, 1) min-max normalization\n",
    "        - 2 (-1, 1) min-max normalization\n",
    "        - 3 mean-std normalization\n",
    "        \"\"\"\n",
    "        super(GradCAM, self).__init__(model)\n",
    "        self.norm_mode = norm_mode\n",
    "        self.global_avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        relu_idxes = self._find_target_layer_idx(module_name=\"convs\", layer_names=[\"relu\"])\n",
    "        self.last_relu_idx = relu_idxes[\"relu\"][-1]\n",
    "        # get Rectified Conv Features Maps\n",
    "        self.f_hook = XaiHook(self.model.convs[self.last_relu_idx])\n",
    "        self.b_hook = XaiHook(self.model.convs[self.last_relu_idx])\n",
    "        self.register_hooks()\n",
    "    \n",
    "    def register_hooks(self):\n",
    "        self._register_forward(self.f_hook, hook_fn=None)\n",
    "        self._register_backward(self.b_hook, hook_fn=None)\n",
    "    \n",
    "    def reset_hooks(self):\n",
    "        self.f_hook.close()\n",
    "        self.b_hook.close()\n",
    "    \n",
    "    def cal_gradcam(self):\n",
    "        # (B, C, H, W) > (B, C, 1, 1)\n",
    "        alpha = self.global_avgpool(self.b_hook.i[0])\n",
    "        # sum( (B, C, 1, 1) * (B, C, H, W) , dim=1) > (B, 1, H, W)\n",
    "        gradcam = torch.relu((alpha * self.f_hook.o).sum(1, keepdim=True))\n",
    "        return gradcam\n",
    "        \n",
    "    def post_processing(self, gradcam, H, W):\n",
    "        \"\"\"\n",
    "        interpolate(up sample) & normalize\n",
    "        https://pytorch.org/docs/stable/nn.functional.html#interpolate\n",
    "        \"\"\"\n",
    "        gradcam = F.interpolate(gradcam, size=(H, W), mode=\"bilinear\", align_corners=False)\n",
    "        gradcam = self.normalization(gradcam)\n",
    "        return gradcam\n",
    "    \n",
    "    def normalization(self, tensor):\n",
    "        B, C, H, W = tensor.size()\n",
    "        tensor = tensor.view(B, -1)\n",
    "        t_min = tensor.min(dim=1, keepdim=True)[0]\n",
    "        t_max = tensor.max(dim=1, keepdim=True)[0]\n",
    "        t_mean = tensor.mean(dim=1, keepdim=True)\n",
    "        t_std = tensor.std(dim=1, keepdim=True)\n",
    "        if self.norm_mode == 1:\n",
    "            tensor -= t_min\n",
    "            tensor /= (t_max - t_min + 1e-10)\n",
    "        elif self.norm_mode == 2:\n",
    "            tensor -= t_min\n",
    "            tensor *= 2\n",
    "            tensor /= (t_max - t_min + 1e-10)\n",
    "        elif self.norm_mode == 3:\n",
    "            tensor -= t_mean\n",
    "            tensor /= t_std\n",
    "        return tensor.view(B, C, H, W)\n",
    "        \n",
    "    def get_attribution(self, x, targets):\n",
    "        *_, H, W = x.size()\n",
    "        self.model.zero_grad()\n",
    "        \n",
    "        output = self.model(x)\n",
    "        grad = self._one_hot(targets, module_name=\"fc\")\n",
    "        output.backward(grad)\n",
    "        \n",
    "        gradcam = self.cal_gradcam()\n",
    "        gradcam = self.post_processing(gradcam, H, W)\n",
    "        \n",
    "        return gradcam.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gradcam_model = GradCAM(model)\n",
    "x = torch.randn(1, 1, 28, 28)\n",
    "targets = torch.LongTensor([2])\n",
    "gradcam = gradcam_model.get_attribution(x, targets)\n",
    "plt.imshow(gradcam.squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GuidedBackprop(XaiModel):\n",
    "    \"\"\"GuidedBackprop\"\"\"\n",
    "    def __init__(self, model):\n",
    "        super(GuidedBackprop, self).__init__(model)\n",
    "        self.register_guided_hooks(self.model.convs)\n",
    "    \n",
    "    def reset_f_outputs(self):\n",
    "        self.f_outputs = []\n",
    "    \n",
    "    def register_guided_hooks(self, layers):\n",
    "        self.relu_f_hooks = []\n",
    "        self.relu_b_hooks = []\n",
    "        self.reset_f_outputs()\n",
    "        for layer in layers:\n",
    "            layer_name = type(layer).__name__\n",
    "            if layer_name.lower() == \"relu\":\n",
    "                f_hook = XaiHook(layer)\n",
    "                b_hook = XaiHook(layer)\n",
    "                self.relu_f_hooks.append(f_hook)\n",
    "                self.relu_b_hooks.append(b_hook)\n",
    "                \n",
    "        def guided_forward(m, i, o):\n",
    "            self.f_outputs.append(o.data)  \n",
    "            \n",
    "        def guided_backward(m, i, o):\n",
    "            deconv_grad = o[0].clamp(min=0)  # o: backward input\n",
    "            forward_output = self.f_outputs.pop(-1)\n",
    "            forward_mask = forward_output.ne(0.0).type_as(forward_output)\n",
    "            grad_in = deconv_grad * forward_mask\n",
    "            return (grad_in, )\n",
    "        \n",
    "        # register forward hooks\n",
    "        self._register_forward(self.relu_f_hooks, hook_fn=guided_forward)\n",
    "        self._register_backward(self.relu_b_hooks, hook_fn=guided_backward)\n",
    "        \n",
    "    def get_attribution(self, x, targets):\n",
    "        x.requires_grad_(True)\n",
    "        output = self.model(x)\n",
    "        grad = self._one_hot(targets, module_name=\"fc\")\n",
    "        output.backward(grad)\n",
    "        x_grad = x.grad.data.clone()\n",
    "        x.requires_grad_(False)\n",
    "        return x_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "guided_model = GuidedBackprop(model)\n",
    "grad = guided_model.get_attribution(x, targets)\n",
    "plt.imshow(grad.squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaGrad(XaiModel):\n",
    "    \"\"\"VanillaGrad\"\"\"\n",
    "    def __init__(self, model):\n",
    "        super(VanillaGrad, self).__init__(model)\n",
    "        \n",
    "    def get_attribution(self, x, target):\n",
    "        \"\"\"vanilla gradient\"\"\"\n",
    "        x.requires_grad_(requires_grad=True)\n",
    "        self.model.zero_grad()\n",
    "        output = self.model(x)\n",
    "        grad = self._one_hot(targets, module_name=\"fc\")\n",
    "        output.backward(grad)\n",
    "        x_grad = x.grad.data.clone()\n",
    "        x.requires_grad_(requires_grad=False)\n",
    "        return x_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vanillagrad = VanillaGrad(model)\n",
    "grad = vanillagrad.get_attribution(x, targets)\n",
    "plt.imshow(grad.squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradInput(XaiModel):\n",
    "    \"\"\"GradInput\"\"\"\n",
    "    def __init__(self, model):\n",
    "        super(GradInput, self).__init__(model)\n",
    "        \n",
    "    def get_attribution(self, x, target):\n",
    "        \"\"\"vanilla gradient*input\"\"\"\n",
    "        x.requires_grad_(requires_grad=True)\n",
    "        self.model.zero_grad()\n",
    "        output = self.model(x)\n",
    "        grad = self._one_hot(targets, module_name=\"fc\")\n",
    "        output.backward(grad)\n",
    "        x_grad = x.grad.data.clone()\n",
    "        x.requires_grad_(requires_grad=False)\n",
    "        \n",
    "        return x_grad * x.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gradinput = GradInput(model)\n",
    "grad = gradinput.get_attribution(x, targets)\n",
    "plt.imshow(grad.squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeconvNet(XaiModel):\n",
    "    \"\"\"DeconvNet\"\"\"\n",
    "    def __init__(self, model, module_name=\"convs\"):\n",
    "        super(DeconvNet, self).__init__(model)\n",
    "        layer_names = [\"conv2d\", \"maxpool2d\"]\n",
    "        self.module_name = module_name\n",
    "        self.deconvs_indices = self.find_idxes(module_name, layer_names)\n",
    "        self.layers = self.make_layers(module_name)\n",
    "        self.init_weights(module_name, layer_name=\"conv2d\")\n",
    "        \n",
    "    def find_idxes(self, module_name, layer_names):\n",
    "        \"\"\"\n",
    "        args:\n",
    "        - module_name\n",
    "        - layer_names: \n",
    "        \n",
    "        return:\n",
    "        get `deconvs_indices` for the `module_name`, \n",
    "        - key: decovnet layer name \n",
    "        - values: indices dict match to {convnet:decovnet}\n",
    "        \"\"\"\n",
    "        convs_indices = self._find_target_layer_idx(module_name, layer_names)\n",
    "        last_layer_num = len(self.model._modules[module_name]) - 1\n",
    "        deconvs_indices = defaultdict(dict)\n",
    "        \n",
    "        for l_name in layer_names:\n",
    "            idxes = (last_layer_num - torch.LongTensor(convs_indices[l_name])).tolist()\n",
    "            deconvs_indices[l_name] = dict(zip(convs_indices[l_name], idxes))\n",
    "            if l_name == \"conv2d\":\n",
    "                deconvs_indices[l_name+\"-bias\"] = dict(zip(\n",
    "                    convs_indices[l_name], idxes[1:]+[None]))\n",
    "            \n",
    "        return deconvs_indices\n",
    "    \n",
    "    def make_layers(self, module_name):\n",
    "        \"\"\"\n",
    "        maxunpool > relu > conv \n",
    "        \"\"\"\n",
    "        layers = []\n",
    "        modules = self.model._modules[module_name]\n",
    "        for layer in modules:\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                temp_layer = nn.ConvTranspose2d(layer.out_channels,\n",
    "                                                layer.in_channels,\n",
    "                                                layer.kernel_size, \n",
    "                                                layer.stride, \n",
    "                                                layer.padding,\n",
    "                                                layer.output_padding,\n",
    "                                                layer.groups, \n",
    "                                                False,  # bias\n",
    "                                                layer.dilation,\n",
    "                                                layer.padding_mode)\n",
    "                layers.append(temp_layer)\n",
    "            elif isinstance(layer, nn.MaxPool2d):\n",
    "                temp_layer = nn.MaxUnpool2d(layer.kernel_size,\n",
    "                                            layer.stride,\n",
    "                                            layer.padding)\n",
    "                layers.append(temp_layer)\n",
    "            else:\n",
    "                layers.append(layer)\n",
    "        return nn.Sequential(*reversed(layers))\n",
    "    \n",
    "    def init_weights(self, module_name, layer_name):\n",
    "        convs = self.model._modules[module_name]\n",
    "        conv_indices = self.deconvs_indices[layer_name]\n",
    "        conv_bias_indices = self.deconvs_indices[layer_name+\"-bias\"]\n",
    "        for i, layer in enumerate(convs):\n",
    "            if type(layer).__name__.lower() == layer_name:\n",
    "                # ex: 3 conv layers (conv, relu, maxpool)\n",
    "                # 'conv2d': {0: 8, 3: 5, 6: 2}\n",
    "                # 'conv2d-bias': {0: 5, 3: 2, 6: None}\n",
    "                \n",
    "                deconv_idx = conv_indices.get(i)\n",
    "                weight = convs[i].weight.data\n",
    "                self.layers[deconv_idx].weight.data = weight\n",
    "                \n",
    "                deconv_bias_idx = conv_bias_indices.get(i)\n",
    "                if deconv_bias_idx is not None:\n",
    "                    bias = convs[i].bias\n",
    "                    self.layers[deconv_bias_idx].bias = bias\n",
    "                \n",
    "                            \n",
    "    def get_attribution(self, x, targets):\n",
    "        unpool_locations = self.deconvs_indices[\"maxpool2d\"]\n",
    "        unpool_locations = {v: k for k, v in unpool_locations.items()}\n",
    "        convs = self.model._modules[self.module_name]\n",
    "\n",
    "        switches = OrderedDict()\n",
    "        self._reset_maps()\n",
    "        self._return_indices(convs, on=True)\n",
    "        for i, layer in enumerate(convs):\n",
    "            if isinstance(layer, nn.MaxPool2d):\n",
    "                x, switch = layer(x)\n",
    "                switches[i] = switch\n",
    "            else:\n",
    "                x = layer(x)\n",
    "                \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            if isinstance(layer, nn.MaxUnpool2d):\n",
    "                j = unpool_locations[i]\n",
    "                x = layer(x, switches[j])\n",
    "            elif isinstance(layer, nn.ConvTranspose2d):\n",
    "                x = layer(x)\n",
    "                layer_name = type(layer).__name__.lower() + f\"-{i}\"\n",
    "                self._save_maps(layer_name, x.data)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        self._return_indices(convs, on=False)\n",
    "        x_ret = x.clone().detach().data\n",
    "        return x_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "deconvnet = DeconvNet(model)\n",
    "deconv = deconvnet.get_attribution(x, targets)\n",
    "plt.imshow(deconv.squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class relLinear(XaiHook):\n",
    "    \"\"\"relLinear\"\"\"\n",
    "    def __init__(self, module, use_rho=False):\n",
    "        \"\"\"\n",
    "        forward\n",
    "        > input: (B, in_f)\n",
    "        > output: (B, out_f)\n",
    "        backward\n",
    "        > lrp propagation with respect to previous input\n",
    "        \"\"\"\n",
    "        super(relLinear, self).__init__(module)\n",
    "        self.out_features = self.module.out_features\n",
    "        self.use_rho = use_rho\n",
    "        self.register_hook(backward=False, hook_fn=self.f_hook)\n",
    "        self.register_hook(backward=True, hook_fn=self.b_hook)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        return self.module(x)\n",
    "    \n",
    "    def f_hook(self, m, i, o):\n",
    "        \"\"\"\n",
    "        forward hook\n",
    "        i: (input,)\n",
    "        o: output\n",
    "        \n",
    "        save forward input and output data\n",
    "        \"\"\"\n",
    "        self.input = i[0].clone().data\n",
    "        self.output = o.clone().data\n",
    "    \n",
    "    def b_hook(self, m, i, o):\n",
    "        \"\"\"\n",
    "        backward hook\n",
    "        i: (grad_bias, grad_input, grad_weight.T) -> backward output\n",
    "        o: (gard_output,) -> backward input\n",
    "        \n",
    "        ### implementation method 1\n",
    "        [Step 1]: (B, in_f, 1) * (1, in_f, out_f) = (B, in_f, out_f)\n",
    "        [Step 2]: (B, 1, out_f), do not multiply `torch.sign(self.output.unsqueeze(1))` \n",
    "                  that returns `nan` in tensor\n",
    "        [Step 3]: divide by s\n",
    "        [Step 4]: (B, in_f, out_f) x (B, out_f, 1) = (B, in_f)\n",
    "        \n",
    "        ```\n",
    "        # Step 1\n",
    "        z = self.input.unsqueeze(-1) * w.transpose(0, 1).unsqueeze(0)\n",
    "        # Step 2\n",
    "        s = self.output.unsqueeze(1) + eps * torch.sign(self.output.unsqueeze(1))  \n",
    "        # Step 3\n",
    "        weight = z / s\n",
    "        # Step 4\n",
    "        r_next = torch.bmm(weight, r.unsqueeze(-1)).squeeze()\n",
    "        ```\n",
    "        ### implemetation method 2\n",
    "        # Step 1: (B, out_f), do not multiply `torch.sign(self.output)` that returns `nan` in tensor\n",
    "        # Step 2: (B, out_f) / (B, out_f) = (B, out_f)\n",
    "        # Step 3: (B, in_f, out_f) * (B, out_f, 1) = (B, in_f)\n",
    "        # Step 4: (B, in_f) x (B, in_f) = (B, in_f)\n",
    "        \n",
    "        ```\n",
    "        # Step 1\n",
    "        s = self.output + eps\n",
    "        # Step 2\n",
    "        e = r / s\n",
    "        # Step 3\n",
    "        c = torch.bmm(w.transpose(0, 1).expand(e.size(0), \n",
    "                                               self.module.in_features, \n",
    "                                               self.module.out_features), \n",
    "                      e.unsqueeze(-1)).squeeze(-1)\n",
    "        # Step 4\n",
    "        r_next = self.input * c\n",
    "        ```\n",
    "        \"\"\"\n",
    "        grad_bias, grad_in, grad_weight = i\n",
    "        r = o[0]\n",
    "        eps = 1e-6\n",
    "        w = self.rho(self.module.weight).data\n",
    "        # Step 1\n",
    "        s = self.output + eps\n",
    "        # Step 2\n",
    "        e = r / s\n",
    "        # Step 3\n",
    "        c = torch.bmm(w.transpose(0, 1).expand(e.size(0), \n",
    "                                               self.module.in_features, \n",
    "                                               self.module.out_features), \n",
    "                      e.unsqueeze(-1)).squeeze(-1)\n",
    "        # Step 4\n",
    "        r_next = self.input * c\n",
    "        assert r_next.size(1) == self.module.in_features, \"size of `r_next` is not correct\"\n",
    "        # for debugging\n",
    "        # self.r = r  \n",
    "        # self.r_next = r_next\n",
    "        return (grad_bias, r_next, grad_weight)\n",
    "#         return r_next\n",
    "        \n",
    "    def rho(self, w):\n",
    "        if self.use_rho:\n",
    "            return torch.clamp(w, min=0)\n",
    "        else:\n",
    "            return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class relReLU(XaiHook):\n",
    "    \"\"\"relReLU\"\"\"\n",
    "    def __init__(self, module):\n",
    "        super(relReLU, self).__init__(module)\n",
    "        self.register_hook(backward=True, hook_fn=self.b_hook)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        return self.module(x)\n",
    "    \n",
    "    def rho(self, w):\n",
    "        if self.use_rho:\n",
    "            return torch.clamp(w, min=0)\n",
    "        else:\n",
    "            return w\n",
    "        \n",
    "    def b_hook(self, m, i, o):\n",
    "        \"\"\"\n",
    "        backward hook\n",
    "        i: (input,) -> backward output\n",
    "        o: (output,) -> backward input\n",
    "        \"\"\"\n",
    "        r = o\n",
    "        return (r,)\n",
    "#         return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class relConv2d(XaiHook):\n",
    "    \"\"\"relConv2d\"\"\"\n",
    "    def __init__(self, module, use_rho=False):\n",
    "        \"\"\"\n",
    "        forward\n",
    "        > input: (B, C_in, H_in, W_in)\n",
    "        > output: (B, C_out, H_out, W_out)\n",
    "        backward\n",
    "        > lrp propagation with respect to previous input\n",
    "        \"\"\"\n",
    "        super(relConv2d, self).__init__(module)\n",
    "        self.use_rho = use_rho\n",
    "        self.register_hook(backward=False, hook_fn=self.f_hook)\n",
    "        self.register_hook(backward=True, hook_fn=self.b_hook)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        return self.module(x)\n",
    "    \n",
    "    def f_hook(self, m, i, o):\n",
    "        \"\"\"\n",
    "        forward hook\n",
    "        i: (input,)\n",
    "        o: output\n",
    "        \n",
    "        save forward input and output data\n",
    "        \"\"\"\n",
    "        self.input = i[0].clone().data\n",
    "        self.output = o.clone().data\n",
    "    \n",
    "    def b_hook(self, m, i, o):\n",
    "        \"\"\"\n",
    "        backward hook\n",
    "        i: (grad_input, grad_weight, gard_bias) -> backward output\n",
    "        o: (gard_output,) -> backward input\n",
    "        \n",
    "        ### implementation method \n",
    "        [Step 1]: (B, C_out, H_out, W_out), do not multiply `torch.sign(self.output)` \n",
    "                   that returns `nan` in tensor\n",
    "        [Step 2]: (B, C_out, H_out, W_out) / (B, C_out, H_out, W_out) = (B, C_out, H_out, W_out)\n",
    "        [Step 3]: (B, C_out, H_out, W_out) --> (B, C_in, H, W)\n",
    "                  same as `self.gradprop(s*e)` or `(s*e).backward(); c=self.input.grad`\n",
    "        [Stpe 4]: (B, C_in, H, W) x (B, C_in, H, W) = (B, C_in, H, W)\n",
    "        \n",
    "        ```\n",
    "        # Step 1\n",
    "        s = self.output + eps \n",
    "        # Step 2\n",
    "        e = r / s\n",
    "        # Step 3:\n",
    "        c = self.gradprop(e, w)\n",
    "        # Step 4\n",
    "        r_next = self.input * c\n",
    "        ```\n",
    "        \"\"\"\n",
    "        _, grad_weight, grad_bias = i\n",
    "        r = o[0]\n",
    "        eps = 1e-6\n",
    "        w = self.rho(self.module.weight)\n",
    "        # Step 1\n",
    "        s = self.output + eps \n",
    "        # Step 2\n",
    "        e = r / s\n",
    "        # Step 3:\n",
    "        c = self.gradprop(e, w)\n",
    "        # Step 4\n",
    "        r_next = self.input * c\n",
    "\n",
    "        # for debugging\n",
    "        # self.r = r  \n",
    "        # self.r_next = r_next\n",
    "        return (r_next, grad_weight, grad_bias)\n",
    "#         return r_next\n",
    "        \n",
    "    def rho(self, w):\n",
    "        if self.use_rho:\n",
    "            return torch.clamp(w, min=0)\n",
    "        else:\n",
    "            return w\n",
    "\n",
    "    def gradprop(self, x, w):\n",
    "        \"\"\"\n",
    "        `ConvTransposed2d` can be seen as the gradient of `Conv2d` with respect to its input.\n",
    "        \"\"\"\n",
    "        output_padding = self.cal_output_padding()\n",
    "        c = torch.nn.functional.conv_transpose2d(x, \n",
    "                                                 weight=w, \n",
    "                                                 stride=self.module.stride, \n",
    "                                                 padding=self.module.padding, \n",
    "                                                 output_padding=output_padding)\n",
    "        return c        \n",
    "\n",
    "    def cal_output_padding(self):\n",
    "        \"\"\"\n",
    "        calculate output_padding size\n",
    "        - size of height or width: (X_in + 2P - K) / S + 1 = X_out\n",
    "        - output_padding = X_in - ((X_out - 1) * S + K - 2P)\n",
    "\n",
    "        * what is output_padding?\n",
    "        from PyTorch Document:\n",
    "        https://pytorch.org/docs/stable/nn.html#convtranspose2d\n",
    "\n",
    "        The padding argument effectively adds `dilation * (kernel_size - 1) - padding` amount of zero padding to \n",
    "        both sizes of the input. This is set so that when a `Conv2d` and a `ConvTranspose2d` are initialized with \n",
    "        same parameters, they are inverses of each other in regard to the input and output shapes. \n",
    "        However, when `stride > 1`, `Conv2d` maps multiple input shapes to the same output shape. \n",
    "        `output_padding` is provided to resolve this ambiguity by effectively increasing \n",
    "        the calculated output shape on one side. Note that output_padding is only used to find output shape, \n",
    "        but does not actually add zero-padding to output.\n",
    "        \"\"\"\n",
    "        H_in, W_in = self.input.size()[2:]\n",
    "        H_out, W_out = self.output.size()[2:]\n",
    "        S_h, S_w = self.module.stride\n",
    "        K_h, K_w = self.module.kernel_size\n",
    "        P_h, P_w = self.module.padding\n",
    "        H_output_padding = H_in - ((H_out - 1)*S_h + K_h - 2*P_h)\n",
    "        W_output_padding = W_in - ((W_out - 1)*S_w + K_w - 2*P_w)\n",
    "        return (H_output_padding, W_output_padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class relMaxPool2d(XaiHook):\n",
    "    \"\"\"relMaxPool2d\"\"\"\n",
    "    def __init__(self, module, use_rho=False):\n",
    "        \"\"\"\n",
    "        forward\n",
    "        > input: (B, C, H_in, W_in)\n",
    "        > output: (B, C, H_out, W_out)\n",
    "        backward\n",
    "        > lrp propagation with respect to previous input\n",
    "        \"\"\"\n",
    "        super(relMaxPool2d, self).__init__(module)\n",
    "        self.use_rho = use_rho\n",
    "        self.register_hook(backward=False, hook_fn=self.f_hook)\n",
    "        self.register_hook(backward=True, hook_fn=self.b_hook)\n",
    "            \n",
    "    def __call__(self, x):\n",
    "        return self.module(x)\n",
    "    \n",
    "    def f_hook(self, m, i, o):\n",
    "        \"\"\"\n",
    "        forward hook\n",
    "        i: (input,)\n",
    "        o: output\n",
    "        \n",
    "        save forward input and output data\n",
    "        \"\"\"\n",
    "        self.input = i[0].clone().data\n",
    "        self.output = o.clone().data\n",
    "        \n",
    "    def b_hook(self, m, i, o):\n",
    "        \"\"\"\n",
    "        backward hook\n",
    "        i: (grad_input,) -> backward output\n",
    "        o: (gard_output,) -> backward input\n",
    "        \n",
    "        ### implementation method \n",
    "        [Step 1]: (B, C, H_out, W_out), do not multiply `torch.sign(self.output)` \n",
    "                  that returns `nan` in tensor\n",
    "        [Step 2]: (B, C, H_out, W_out) / (B, C, H_out, W_out) = (B, C, H_out, W_out)\n",
    "        [Step 3]: (B, C, H_out, W_out) --> (B, C, H_in, W_in)\n",
    "                  same as `self.gradprop(s*e)` or `(s*e).backward(); c=self.input.grad`\n",
    "        [Stpe 4]: (B, C, H_in, W_in) x (B, C, H_in, W_in) = (B, C, H_in, W_in)\n",
    "        \n",
    "        ```\n",
    "        # Step 1\n",
    "        s = self.output + eps \n",
    "        # Step 2\n",
    "        e = r / s\n",
    "        # Step 3:\n",
    "        c = self.gradprop(e)\n",
    "        # Step 4\n",
    "        r_next = self.input * c\n",
    "        ```\n",
    "        \"\"\"        \n",
    "        r = o[0]\n",
    "        eps = 1e-6\n",
    "        # Step 1\n",
    "        s = self.output + eps\n",
    "        # Step 2\n",
    "        e = r / s\n",
    "        # Step 3\n",
    "        c = self.gradprop(e)\n",
    "        # Step 4\n",
    "        r_next = self.input * c\n",
    "        \n",
    "        # for debugging\n",
    "        # self.r = r  \n",
    "        # self.r_next = r_next\n",
    "        return (r_next,)\n",
    "#         return r_next\n",
    "    \n",
    "    def gradprop(self, x):\n",
    "        \"\"\"\n",
    "        get maxpooled switches first then unpool\n",
    "        \"\"\"\n",
    "        _, switches = torch.nn.functional.max_pool2d(self.input, \n",
    "                                                     self.module.kernel_size, \n",
    "                                                     self.module.stride, \n",
    "                                                     self.module.padding, \n",
    "                                                     self.module.dilation, \n",
    "                                                     self.module.ceil_mode, \n",
    "                                                     return_indices=True)\n",
    "        c = torch.nn.functional.max_unpool2d(x, switches, \n",
    "                                             self.module.kernel_size, \n",
    "                                             self.module.stride, \n",
    "                                             self.module.padding)\n",
    "        return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRP(XaiModel):\n",
    "    \"\"\"LRP\"\"\"\n",
    "    def __init__(self, model, module_names, use_rho=False):\n",
    "        \"\"\"\n",
    "        module_names: have to be sequential to forward network \n",
    "        \"\"\"\n",
    "        super(LRP, self).__init__(model)\n",
    "        self.module_names = module_names\n",
    "        self.use_rho = use_rho\n",
    "        self.available_module = {\n",
    "            nn.Linear: relLinear, \n",
    "            nn.Conv2d: relConv2d, \n",
    "            nn.MaxPool2d: relMaxPool2d, \n",
    "            nn.ReLU: relReLU\n",
    "        }\n",
    "        self.create_layers()\n",
    "        \n",
    "    def create_layers(self):\n",
    "#         modules = self.model._modules[module_name]\n",
    "        \n",
    "#         self.convs = \n",
    "        for module_name in self.module_names:\n",
    "            modules = self.model._modules[module_name]\n",
    "            layers = []\n",
    "            if isinstance(modules, nn.Sequential):\n",
    "                for i, layer in enumerate(modules):\n",
    "                    try:\n",
    "                        layers.append(self._create_layer(layer))\n",
    "                    except KeyError as e:\n",
    "                        print(f\"{type(layer)} is not an available module.\\nAvaiable:\")\n",
    "                        for k in self.available_module.keys():\n",
    "                            print(f\" - {k}\")\n",
    "                layers = nn.Sequential(*layers)\n",
    "            else:\n",
    "                layers = self._create_layer(layer)\n",
    "            self.__setattr__(module_name, layers)        \n",
    "        \n",
    "    def _create_layer(self, layer):\n",
    "        if isinstance(layer, nn.ReLU):\n",
    "            return self.available_module[type(layer)](layer)\n",
    "        else:\n",
    "            return self.available_module[type(layer)](layer, use_rho=self.use_rho)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        x = self.convs(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "        \n",
    "    def get_attribution(self, x, targets):\n",
    "        x.requires_grad_(requires_grad=True)\n",
    "        self.model.zero_grad()\n",
    "        output = self.forward(x)\n",
    "        grad = self._one_hot(targets, module_name=\"fc\")\n",
    "        output.backward(grad)\n",
    "        x_grad = x.grad.data.clone()\n",
    "        x.requires_grad_(requires_grad=False)\n",
    "        return x_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): relConv2d(\n",
       "    (module): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  )\n",
       "  (1): relReLU(\n",
       "    (module): ReLU()\n",
       "  )\n",
       "  (2): relMaxPool2d(\n",
       "    (module): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (3): relConv2d(\n",
       "    (module): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  )\n",
       "  (4): relReLU(\n",
       "    (module): ReLU()\n",
       "  )\n",
       "  (5): relMaxPool2d(\n",
       "    (module): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (6): relConv2d(\n",
       "    (module): Conv2d(64, 128, kernel_size=(2, 2), stride=(1, 1))\n",
       "  )\n",
       "  (7): relReLU(\n",
       "    (module): ReLU()\n",
       "  )\n",
       "  (8): relMaxPool2d(\n",
       "    (module): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrp.convs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected Variable, but hook returned 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-ccf5c8f1f84a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodule_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"convs\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"fc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlrp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLRP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mx_lrp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlrp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attribution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_lrp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-ec6bb967845f>\u001b[0m in \u001b[0;36mget_attribution\u001b[1;34m(self, x, targets)\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_one_hot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"fc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[0mx_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \"\"\"\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected Variable, but hook returned 'tuple'"
     ]
    }
   ],
   "source": [
    "module_names = [\"convs\", \"fc\"]\n",
    "lrp = LRP(model, module_names)\n",
    "x_lrp = lrp.get_attribution(x, targets)\n",
    "plt.imshow(x_lrp.squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = lrp._one_hot(targets, module_name=\"fc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "o1 = lrp.model.convs(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "o2 = o1.view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3 = lrp.model.fc(o2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = lrp.model.fc[0](o2)\n",
    "t2 = lrp.model.fc[1](t1)\n",
    "t3 = lrp.model.fc[2](t2)\n",
    "t3.backward(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3.backward(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0600, -0.0980, -0.0126, -0.0029,  0.0214, -0.0364,  0.0844, -0.1080,\n",
       "          0.0265, -0.1635]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrp.model(torch.randn(1, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrp.model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class abc():\n",
    "    def __init__(self):\n",
    "        self.a  = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = abc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.__setattr__(\"b\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (4): ReLU()\n",
       "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (6): Conv2d(64, 128, kernel_size=(2, 2), stride=(1, 1))\n",
       "  (7): ReLU()\n",
       "  (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__setattr__(\"convs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRP(nn.Module):\n",
    "    \"\"\"LRP\"\"\"\n",
    "    def __init__(self, model):\n",
    "        super(LRP, self).__init__()\n",
    "        # lrp\n",
    "        self.activation_func = model.activation_func\n",
    "        self.model_type = model.model_type\n",
    "        self.activation_type = model.activation_type\n",
    "        \n",
    "        self.layers = self.lrp_make_layers(model)\n",
    "        \n",
    "    def reset_activation_maps(self):\n",
    "        self.activation_maps = OrderedDict()\n",
    "\n",
    "    def lrp_make_layers(self, model):\n",
    "        layers = []\n",
    "        mapping_dict = {nn.Linear: relLinear, nn.Conv2d: relConv2d, nn.MaxPool2d: relMaxPool2d, \n",
    "                        nn.ReLU: relReLU}\n",
    "        for layer in model.layers:\n",
    "            if isinstance(layer, Reshape):\n",
    "                layers.append(layer)\n",
    "            else:\n",
    "                layers.append(mapping_dict[layer.__class__](layer))\n",
    "                \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        lrp method\n",
    "        must run forward first to save input and output at each layer\n",
    "        \"\"\"\n",
    "        self.reset_activation_maps()\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    def save_activation_maps(self, layer, typ, idx, x):\n",
    "        if isinstance(layer, typ):\n",
    "            layer_name = f\"({idx}) {str(layer).split('(')[0]}\"\n",
    "            self.activation_maps[layer_name] = x\n",
    "    \n",
    "    def get_attribution(self, x, target=None, store=False, use_rho=False):\n",
    "        \"\"\"\n",
    "        store: if True, save activation maps\n",
    "        \"\"\"\n",
    "        o = self.forward(x).detach()\n",
    "        r = o * torch.zeros_like(o).scatter(1, o.argmax(1, keepdim=True), 1)\n",
    "        for idx, layer in enumerate(self.layers[::-1]):\n",
    "            r = layer.relprop(r, use_rho)\n",
    "            if store:\n",
    "                self.save_activation_maps(layer, relConv2d, idx, r)\n",
    "        return r.detach()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
