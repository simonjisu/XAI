{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from copy import deepcopy\n",
    "from collections import OrderedDict\n",
    "\n",
    "class XaiBase(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XaiBase, self).__init__()\n",
    "        \"\"\"\n",
    "        need to define hook function at each method\n",
    "        - f_hook\n",
    "        - b_hook\n",
    "        \"\"\"\n",
    "        self._reset_maps()\n",
    "        self.handlers = list()\n",
    "    \n",
    "    def _reset_maps(self):\n",
    "        self.maps = OrderedDict()\n",
    "        \n",
    "    def _save_maps(self, layer_name, x):\n",
    "        self.maps[layer_name] = x    \n",
    "    \n",
    "    def _reset_handlers(self):\n",
    "        for handle in self.handlers:\n",
    "            handle.remove()\n",
    "        self.handlers = []\n",
    "                \n",
    "    def _register(self, layers, registor_type=\"both\"):\n",
    "        \"\"\"\n",
    "        need to define hook functions to use\n",
    "         - both: registor both forward and backward\n",
    "         - f: registor forward\n",
    "         - b: registor backward\n",
    "        \n",
    "        def f_hook(self, *x):\n",
    "            '''\n",
    "            m: module name\n",
    "            i: forward input\n",
    "            o: forward output\n",
    "            '''\n",
    "            m, i, o = x\n",
    "        \n",
    "        def b_hook(self, *x):\n",
    "            '''\n",
    "            m: module name\n",
    "            i: gradient input\n",
    "            o: gradient output\n",
    "            '''\n",
    "            m, i, o = x\n",
    "        \"\"\"\n",
    "        for layer in layers:\n",
    "            if registor_type == \"both\":\n",
    "                handle1 = layer.register_forward_hook(self.f_hook)\n",
    "                handle2 = layer.register_backward_hook(self.b_hook)\n",
    "                self.handlers.append(handle1)\n",
    "                self.handlers.append(handle2)\n",
    "            elif registor_type == \"f\":\n",
    "                handle1 = layer.register_forward_hook(self.f_hook)\n",
    "                self.handlers.append(handle1)\n",
    "            elif registor_type == \"b\":\n",
    "                handle2 = layer.register_backward_hook(self.b_hook)\n",
    "                self.handlers.append(handle2)\n",
    "\n",
    "    def _return_indices(self, layers, on=True):\n",
    "        \"\"\"\n",
    "        support for cnn layer which have `nn.MaxPool2d`,\n",
    "        you can turn on/off pooling indices.\n",
    "        please define a forward function to use it in your model\n",
    "        '''\n",
    "        # in your model\n",
    "        def forward_switch(self, x):\n",
    "            switches = OrderedDict()\n",
    "            self.return_indices(on=True)\n",
    "            for idx, layer in enumerate(self.convs):\n",
    "                if isinstance(layer, nn.MaxPool2d):\n",
    "                    x, indices = layer(x)\n",
    "                    switches[idx] = indices\n",
    "                else:\n",
    "                    x = layer(x)\n",
    "            self.return_indices(on=False)\n",
    "            return x, switches\n",
    "        '''\n",
    "        \"\"\"\n",
    "        if on:\n",
    "            for layer in layers:\n",
    "                if isinstance(layer, nn.MaxPool2d):\n",
    "                    layer.return_indices = True\n",
    "        else:\n",
    "            for layer in layers:\n",
    "                if isinstance(layer, nn.MaxPool2d):\n",
    "                    layer.return_indices = False  \n",
    "                    \n",
    "                    \n",
    "class XaiModel(XaiBase):\n",
    "    def __init__(self, model):\n",
    "        super(XaiModel, self).__init__()\n",
    "        self.model = deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelAttention(nn.Module):\n",
    "    \"\"\"Channel Attention Module\"\"\"\n",
    "    def __init__(self, C, H, W, ratio):\n",
    "        \"\"\"\n",
    "        Method in [arXiv:1807.06521]\n",
    "        args:\n",
    "         - C: channel of input features\n",
    "         - H: height of input features\n",
    "         - W: width of input features\n",
    "         - hid_size: hidden size of shallow network\n",
    "         - ratio: reduction ratio\n",
    "        \"\"\"\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        assert isinstance(2*C // ratio, int), \"`2*C // ratio` must be int \"\n",
    "        kernel_size = (H, W)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size)\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size)\n",
    "        self.shallow_net = nn.Sequential(\n",
    "            nn.Linear(2*C, 2*C // ratio),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2*C // ratio, 2*C),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # (B, C, H, W) > (B, 2*C, 1, 1)\n",
    "        x = torch.cat([self.maxpool(x), self.avgpool(x)], dim=1)\n",
    "        # (B, 2*C) > (B, 2*C//2) > (B, 2*C)\n",
    "        x = self.shallow_net(x.squeeze(-1).squeeze(-1))\n",
    "        # (B, C), (B, C)\n",
    "        x_max, x_avg = torch.chunk(x, 2, dim=1)\n",
    "        # not using softmax in paper: something like gate function\n",
    "        x = torch.sigmoid(x_max + x_avg)\n",
    "        return x.unsqueeze(-1).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialAttention(nn.Module):\n",
    "    \"\"\"Spatial Attention Module\"\"\"\n",
    "    def __init__(self, H, W, K_H=7, K_W=7, S_H=1, S_W=1):\n",
    "        \"\"\"\n",
    "        Method in [arXiv:1807.06521]\n",
    "        args:\n",
    "         - H: height of input features\n",
    "         - W: width of input features\n",
    "         - K_H: height of kernel size\n",
    "         - K_W: width of kernel size\n",
    "         - S_H: stride height of conv layer\n",
    "         - S_W: stride width of conv layer\n",
    "        \"\"\"\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        P_H = self.cal_padding_size(H, K_H, S_H)\n",
    "        P_W = self.cal_padding_size(W, K_W, S_W)\n",
    "        kernel_size = (K_H, K_W)\n",
    "        stride = (S_H, S_W)\n",
    "        padding = (P_H, P_W)\n",
    "        # same padding conv layer\n",
    "        self.conv_layer = nn.Conv2d(2, 1, kernel_size, stride, padding)\n",
    "    \n",
    "    def cal_padding_size(self, x, K, S):\n",
    "        return int((S * (x-1) + K - x) / 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # (B, C, H, W) > (B, 1, H, W)\n",
    "        x_max, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x_avg = torch.mean(x, dim=1, keepdim=True)\n",
    "        # (B, 2, H, W)\n",
    "        x = torch.cat([x_max, x_avg], dim=1)\n",
    "        # (B, 2, H, W) > (B, 1, H, W)\n",
    "        x = self.conv_layer(x)\n",
    "        # return gated features\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBAM(nn.Module):\n",
    "    \"\"\"Convolution Block Attention Module\"\"\"\n",
    "    def __init__(self, C, H, W, ratio, K_H=7, K_W=7, S_H=1, S_W=1):\n",
    "        \"\"\"\n",
    "        Method in [arXiv:1807.06521]\n",
    "        args:\n",
    "         - C: channel of input features\n",
    "         - H: height of input features\n",
    "         - W: width of input features\n",
    "         - ratio: reduction ratio\n",
    "         - K_H: height of kernel size\n",
    "         - K_W: width of kernel size\n",
    "         - S_H: stride height of conv layer\n",
    "         - S_W: stride width of conv layer\n",
    "         \n",
    "        return:\n",
    "         - attentioned features, size = (B, C, H, W)\n",
    "        \"\"\"\n",
    "        super(CBAM, self).__init__()\n",
    "        self.channel_attn = ChannelAttention(C, H, W, ratio)\n",
    "        self.spatial_attn = SpatialAttention(H, W, K_H, K_W, S_H, S_W)\n",
    "        \n",
    "    def forward(self, x, return_attn=False):\n",
    "        \"\"\"\n",
    "        return: attentioned features, size = (B, C, H, W)\n",
    "        \"\"\"\n",
    "        out = x\n",
    "        c_attn = self.channel_attn(out)\n",
    "        out = c_attn * out\n",
    "        s_attn = self.spatial_attn(out)\n",
    "        out = s_attn * out\n",
    "        if return_attn:\n",
    "            return out, (c_attn, s_attn)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "\n",
    "class CnnWithCBAM(XaiBase):\n",
    "    def __init__(self, activation_type):\n",
    "        \"\"\"\n",
    "        activation_type: \"relu\", \"tanh\", \"sigmoid\", \"softplus\"\n",
    "        \"\"\"\n",
    "        super(CnnWithCBAM, self).__init__()\n",
    "        act = {\"relu\": nn.ReLU, \n",
    "               \"tanh\": nn.Tanh, \n",
    "               \"sigmoid\": nn.Sigmoid, \n",
    "               \"softplus\": nn.Softplus}\n",
    "        self.activation_func = act[activation_type]\n",
    "        \n",
    "        self.convs = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 5),  # (B, 1, 32, 32) > (B, 32, 28, 28)\n",
    "            CBAM(32, 28, 28, 16),\n",
    "            self.activation_func(),\n",
    "            nn.MaxPool2d(2),  # (B, 32, 28, 28) > (B, 32, 14, 14)\n",
    "            nn.Conv2d(32, 64, 3),  # (B, 32, 14, 14) > (B, 64, 12, 12)\n",
    "            CBAM(64, 12, 12, 16),\n",
    "            self.activation_func(), \n",
    "            nn.MaxPool2d(2),  # (B, 64, 12, 12) > (B, 64, 6, 6)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64*6*6, 128),\n",
    "            self.activation_func(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):        \n",
    "        x = self.convs(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    def forward_map(self, x):\n",
    "        self._reset_maps()\n",
    "        for i, layer in enumerate(self.convs):\n",
    "            layer_name = type(layer).__name__\n",
    "            if layer_name == \"CBAM\":\n",
    "                x, attns = layer(x, return_attn=True)\n",
    "                self._save_maps(f\"{i}\"+layer_name, attns)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CnnWithCBAM(\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCAM(XaiModel):\n",
    "    def __init__(self, model):\n",
    "        super(GradCAM, self).__init__(model)\n",
    "    \n",
    "    def f_hook(self, x):\n",
    "        m, i, o = x\n",
    "        return m\n",
    "    \n",
    "    def b_hook(self, x):\n",
    "        m, i, o = x\n",
    "        return m\n",
    "    \n",
    "    def get_attribution(self, x):\n",
    "        for layer in self.model.convs:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradcam = GradCAM(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradcam._register(gradcam.model.convs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "f_hook() takes 2 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-a001a515628a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradcam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/venv/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhook_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: f_hook() takes 2 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "x = gradcam.model.convs(torch.rand(1, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
