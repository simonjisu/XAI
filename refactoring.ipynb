{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict, OrderedDict\n",
    "\n",
    "class XaiHook(object):\n",
    "    def __init__(self, module):\n",
    "        \"\"\"\n",
    "        Hook Handler Module\n",
    "        \n",
    "        supported register `module` hooks\n",
    "        - Activations\n",
    "        - Linear\n",
    "        - Convd\n",
    "        \n",
    "        like RNN have to use `register_hook` to `torch.nn.Parameter` directly\n",
    "        \n",
    "        * Ref: https://pytorch.org/docs/master/nn.html#torch.nn.Module.register_backward_hook\n",
    "        [Warnings]\n",
    "        The current implementation will not have the presented behavior \n",
    "        for complex Module that perform many operations. In some failure cases, \n",
    "        `grad_input` and `grad_output` will only contain the gradients for a subset\n",
    "        of the inputs and outputs. For such `Module`, you should use \n",
    "        `torch.Tensor.register_hook()` directly on a specific input or \n",
    "        output to get the required gradients.\n",
    "        \n",
    "        \"\"\"\n",
    "        self.module = module\n",
    "        \n",
    "    def register_hook(self, backward=False, hook_fn=None):\n",
    "        \"\"\"\n",
    "        defalut hook_function is save (module, input, output) to (m, i, o)\n",
    "        if you want to use hook function, change `hook_function` \n",
    "        if `hook_function` returns `None` then the original input or output \n",
    "        will be flow into next / previous layer, but you can return a modifed\n",
    "        output or gradient.\n",
    "        for a Conv2d layer example\n",
    "        - forward: a `Tensor` type output\n",
    "        - backward: (gradient_input, weight, bias)\n",
    "        \n",
    "        \"\"\"\n",
    "        def default_hook_fn(m, i, o):\n",
    "            \"\"\"\n",
    "            forward\n",
    "             - m: module class\n",
    "             - i: forward input from previous layer\n",
    "             - o: forward output to next layer\n",
    "            backward\n",
    "             - m: module class\n",
    "             - i: gradient input to next layer (backward out)\n",
    "             - o: gradient output from previous layer (backward in)\n",
    "\n",
    "            args:\n",
    "             * i, o: tuple type\n",
    "            \"\"\"\n",
    "            self.m = m\n",
    "            self.i = i\n",
    "            self.o = o\n",
    "            \n",
    "        if hook_fn is None:\n",
    "            self.hook_fn = default_hook_fn\n",
    "        else:\n",
    "            self.hook_fn = hook_fn\n",
    "        if not backward:\n",
    "            self.hook = self.module.register_forward_hook(self.hook_fn)\n",
    "        else:\n",
    "            self.hook = self.module.register_backward_hook(self.hook_fn)\n",
    "            \n",
    "\n",
    "        \n",
    "    def close(self):\n",
    "        self.hook.remove()\n",
    "\n",
    "\n",
    "class XaiBase(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XaiBase, self).__init__()\n",
    "        \"\"\"\n",
    "        - need to define XaiHook class to use\n",
    "        - defalut hook_function is save (module, input, output) to (m, i, o)\n",
    "          if you want to use hook function, change `hook_function` \n",
    "        \"\"\"\n",
    "        self._reset_maps()\n",
    "    \n",
    "    def _reset_maps(self):\n",
    "        self.maps = OrderedDict()\n",
    "        \n",
    "    def _save_maps(self, layer_name, x):\n",
    "        self.maps[layer_name] = x    \n",
    "        \n",
    "    def _register(self, hooks, backward=False, hook_fn=None):\n",
    "        \"\"\"\n",
    "        - need to define XaiHook class to use\n",
    "        - defalut hook_function is save (module, input, output) to (m, i, o)\n",
    "          if you want to use hook function, change `hook_function` \n",
    "        \"\"\"\n",
    "        if not isinstance(hooks, list):\n",
    "            hooks = [hooks]\n",
    "        for hook in hooks:\n",
    "            hook.register_hook(backward=backward, hook_fn=hook_fn)\n",
    "    \n",
    "    def _register_forward(self, hooks, hook_fn=None):\n",
    "        self._register(hooks, backward=False, hook_fn=hook_fn)\n",
    "        \n",
    "    def _register_backward(self, hooks, hook_fn=None):\n",
    "        self._register(hooks, backward=True, hook_fn=hook_fn)\n",
    "    \n",
    "    def _reset_hooks(self, hooks):\n",
    "        if not isinstance(hooks, list):\n",
    "            hooks = [hooks]\n",
    "        for hook in hooks:\n",
    "            hook.close()\n",
    "\n",
    "    def _return_indices(self, layers, on=True):\n",
    "        \"\"\"\n",
    "        support for cnn layer which have `nn.MaxPool2d`,\n",
    "        you can turn on/off pooling indices.\n",
    "        please define a forward function to use it in your model\n",
    "        '''\n",
    "        # in your model\n",
    "        def forward_switch(self, x):\n",
    "            switches = OrderedDict()\n",
    "            self.return_indices(on=True)\n",
    "            for idx, layer in enumerate(self.convs):\n",
    "                if isinstance(layer, nn.MaxPool2d):\n",
    "                    x, indices = layer(x)\n",
    "                    switches[idx] = indices\n",
    "                else:\n",
    "                    x = layer(x)\n",
    "            self.return_indices(on=False)\n",
    "            return x, switches\n",
    "        '''\n",
    "        \"\"\"\n",
    "        if on:\n",
    "            for layer in layers:\n",
    "                if isinstance(layer, nn.MaxPool2d):\n",
    "                    layer.return_indices = True\n",
    "        else:\n",
    "            for layer in layers:\n",
    "                if isinstance(layer, nn.MaxPool2d):\n",
    "                    layer.return_indices = False  \n",
    "                    \n",
    "                    \n",
    "class XaiModel(XaiBase):\n",
    "    def __init__(self, model):\n",
    "        super(XaiModel, self).__init__()\n",
    "        self.model = deepcopy(model)\n",
    "        self.model.cpu()\n",
    "        self.model.eval()\n",
    "        \n",
    "    def _one_hot(self, targets, module_name):\n",
    "        \"\"\"\n",
    "        one hot vectorize the target tensor\n",
    "        args:\n",
    "        - targets: torch.LongTensor, target classes that have size of mini-batch\n",
    "        - module_name: str, feature name for Fully-Connected Network or any Task-specific Network\n",
    "        return:\n",
    "        - one hot vector of targets\n",
    "        \"\"\"\n",
    "        assert isinstance(targets, torch.LongTensor), \"`targets` must be `torch.LongTensor` type\"\n",
    "        assert isinstance(module_name, str), \"`module_name` must be `str` type\"\n",
    "        modules = self.model._modules[module_name]\n",
    "        if isinstance(modules, nn.Sequential):\n",
    "            last_layer = modules[-1]\n",
    "        else:\n",
    "            last_layer = modules\n",
    "        assert isinstance(last_layer, nn.Linear), \"`last layer` must be `torch.nn.Linear`\"\n",
    "        target_size = self.model._modules[module_name][-1].out_features\n",
    "        B = targets.size(0)\n",
    "        one_hot = torch.zeros((B, target_size))\n",
    "        one_hot.scatter_(1, targets.unsqueeze(1), 1.0)\n",
    "        return one_hot.to(targets.device)\n",
    "    \n",
    "    def _find_target_layer_idx(self, module_name, layer_names):\n",
    "        assert isinstance(layer_names, list) or isinstance(layer_names, tuple), \"use list for `layer_names`\"\n",
    "        layer_names = [l.lower() for l in layer_names]\n",
    "        idxes = defaultdict(list)\n",
    "        modules = self.model._modules[module_name]\n",
    "        assert isinstance(modules, nn.Sequential), \"use this function for `nn.Sequential` type modules\"\n",
    "        for idx, layer in modules.named_children():\n",
    "            l_name = type(layer).__name__.lower()\n",
    "            if l_name in layer_names:\n",
    "                idxes[l_name].append(int(idx))\n",
    "\n",
    "        return idxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelAttention(nn.Module):\n",
    "    \"\"\"Channel Attention Module\"\"\"\n",
    "    def __init__(self, C, ratio):\n",
    "        \"\"\"\n",
    "        Method in [arXiv:1807.06521]\n",
    "        args:\n",
    "         - C: channel of input features\n",
    "         - H: height of input features\n",
    "         - W: width of input features\n",
    "         - hid_size: hidden size of shallow network\n",
    "         - ratio: reduction ratio\n",
    "        \"\"\"\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        assert isinstance(2*C // ratio, int), \"`2*C // ratio` must be int \"\n",
    "        self.maxpool = nn.AdaptiveMaxPool2d((1, 1))\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.shallow_net = nn.Sequential(\n",
    "            nn.Linear(2*C, 2*C // ratio),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2*C // ratio, 2*C),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # (B, C, H, W) > (B, 2*C, 1, 1)\n",
    "        x = torch.cat([self.maxpool(x), self.avgpool(x)], dim=1)\n",
    "        # (B, 2*C) > (B, 2*C//2) > (B, 2*C)\n",
    "        x = self.shallow_net(x.squeeze(-1).squeeze(-1))\n",
    "        # (B, C), (B, C)\n",
    "        x_max, x_avg = torch.chunk(x, 2, dim=1)\n",
    "        # not using softmax in paper: something like gate function\n",
    "        x = torch.sigmoid(x_max + x_avg)\n",
    "        return x.unsqueeze(-1).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialAttention(nn.Module):\n",
    "    \"\"\"Spatial Attention Module\"\"\"\n",
    "    def __init__(self, H, W, K_H=7, K_W=7, S_H=1, S_W=1):\n",
    "        \"\"\"\n",
    "        Method in [arXiv:1807.06521]\n",
    "        args:\n",
    "         - H: height of input features\n",
    "         - W: width of input features\n",
    "         - K_H: height of kernel size\n",
    "         - K_W: width of kernel size\n",
    "         - S_H: stride height of conv layer\n",
    "         - S_W: stride width of conv layer\n",
    "        \"\"\"\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        P_H = self.cal_padding_size(H, K_H, S_H)\n",
    "        P_W = self.cal_padding_size(W, K_W, S_W)\n",
    "        kernel_size = (K_H, K_W)\n",
    "        stride = (S_H, S_W)\n",
    "        padding = (P_H, P_W)\n",
    "        # same padding conv layer\n",
    "        self.conv_layer = nn.Conv2d(2, 1, kernel_size, stride, padding)\n",
    "    \n",
    "    def cal_padding_size(self, x, K, S):\n",
    "        return int((S * (x-1) + K - x) / 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # (B, C, H, W) > (B, 1, H, W)\n",
    "        x_max, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x_avg = torch.mean(x, dim=1, keepdim=True)\n",
    "        # (B, 2, H, W)\n",
    "        x = torch.cat([x_max, x_avg], dim=1)\n",
    "        # (B, 2, H, W) > (B, 1, H, W)\n",
    "        x = self.conv_layer(x)\n",
    "        # return gated features\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBAM(nn.Module):\n",
    "    \"\"\"Convolution Block Attention Module\"\"\"\n",
    "    def __init__(self, C, H, W, ratio, K_H=7, K_W=7, S_H=1, S_W=1):\n",
    "        \"\"\"\n",
    "        Method in [arXiv:1807.06521]\n",
    "        args:\n",
    "         - C: channel of input features\n",
    "         - H: height of input features\n",
    "         - W: width of input features\n",
    "         - ratio: reduction ratio\n",
    "         - K_H: height of kernel size\n",
    "         - K_W: width of kernel size\n",
    "         - S_H: stride height of conv layer\n",
    "         - S_W: stride width of conv layer\n",
    "         \n",
    "        return:\n",
    "         - attentioned features, size = (B, C, H, W)\n",
    "        \"\"\"\n",
    "        super(CBAM, self).__init__()\n",
    "        self.channel_attn = ChannelAttention(C, ratio)\n",
    "        self.spatial_attn = SpatialAttention(H, W, K_H, K_W, S_H, S_W)\n",
    "        \n",
    "    def forward(self, x, return_attn=False):\n",
    "        \"\"\"\n",
    "        return: attentioned features, size = (B, C, H, W)\n",
    "        \"\"\"\n",
    "        out = x\n",
    "        c_attn = self.channel_attn(out)\n",
    "        out = c_attn * out\n",
    "        s_attn = self.spatial_attn(out)\n",
    "        out = s_attn * out\n",
    "        if return_attn:\n",
    "            return out, (c_attn, s_attn)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "\n",
    "class CnnWithCBAM(XaiBase):\n",
    "    def __init__(self):\n",
    "        super(CnnWithCBAM, self).__init__()\n",
    "\n",
    "        self.convs = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 5),  # (B, 1, 28, 28) > (B, 32, 24, 24)\n",
    "            CBAM(32, 24, 24, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # (B, 32, 24, 24) > (B, 32, 12, 12)\n",
    "            nn.Conv2d(32, 64, 3),  # (B, 32, 12, 12) > (B, 64, 10, 10)\n",
    "            CBAM(64, 10, 10, 16),\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(2),  # (B, 64, 10, 10) > (B, 64, 5, 5)\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64*5*5, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):        \n",
    "        x = self.convs(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    def forward_map(self, x):\n",
    "        self._reset_maps()\n",
    "        for i, layer in enumerate(self.convs):\n",
    "            layer_name = type(layer).__name__.lower()\n",
    "            if layer_name == \"cbam\":\n",
    "                x, attns = layer(x, return_attn=True)\n",
    "                self._save_maps(f\"{i}\"+layer_name, attns)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cnn(XaiBase):\n",
    "    def __init__(self):\n",
    "        super(Cnn, self).__init__()\n",
    "\n",
    "        self.convs = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 5),  # (B, 1, 28, 28) > (B, 32, 24, 24)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # (B, 32, 24, 24) > (B, 32, 12, 12)\n",
    "            nn.Conv2d(32, 64, 3),  # (B, 32, 12, 12) > (B, 64, 10, 10)\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(2),  # (B, 64, 10, 10) > (B, 64, 5, 5)\n",
    "            nn.Conv2d(64, 128, 2),  # (B, 128, 5, 5) > (B, 128, 4, 4)\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(2),  # (B, 128, 4, 4) > (B, 128, 2, 2)\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128*2*2, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):        \n",
    "        x = self.convs(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    def forward_map(self, x):\n",
    "        self._reset_maps()\n",
    "        for i, layer in enumerate(self.convs):\n",
    "            layer_name = type(layer).__name__.lower()\n",
    "            if layer_name == \"relu\":\n",
    "                x, attns = layer(x, return_attn=True)\n",
    "                self._save_maps(f\"{i}\"+layer_name, attns)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CnnWithCBAM()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class GradCAM(XaiModel):\n",
    "    \"\"\"GradCAM\"\"\"\n",
    "    def __init__(self, model, norm_mode=1):\n",
    "        \"\"\"\n",
    "        norm mode\n",
    "        - 1 ( 0, 1) min-max normalization\n",
    "        - 2 (-1, 1) min-max normalization\n",
    "        - 3 mean-std normalization\n",
    "        \"\"\"\n",
    "        super(GradCAM, self).__init__(model)\n",
    "        self.norm_mode = norm_mode\n",
    "        self.global_avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        relu_idxes = self._find_target_layer_idx(module_name=\"convs\", layer_names=[\"relu\"])\n",
    "        self.last_relu_idx = relu_idxes[\"relu\"][-1]\n",
    "        # get Rectified Conv Features Maps\n",
    "        self.f_hook = XaiHook(self.model.convs[self.last_relu_idx])\n",
    "        self.b_hook = XaiHook(self.model.convs[self.last_relu_idx])\n",
    "        self.register_hooks()\n",
    "    \n",
    "    def register_hooks(self):\n",
    "        self._register_forward(self.f_hook, hook_fn=None)\n",
    "        self._register_backward(self.b_hook, hook_fn=None)\n",
    "    \n",
    "    def reset_hooks(self):\n",
    "        self.f_hook.close()\n",
    "        self.b_hook.close()\n",
    "    \n",
    "    def cal_gradcam(self):\n",
    "        # (B, C, H, W) > (B, C, 1, 1)\n",
    "        alpha = self.global_avgpool(self.b_hook.i[0])\n",
    "        # sum( (B, C, 1, 1) * (B, C, H, W) , dim=1) > (B, 1, H, W)\n",
    "        gradcam = torch.relu((alpha * self.f_hook.o).sum(1, keepdim=True))\n",
    "        return gradcam\n",
    "        \n",
    "    def post_processing(self, gradcam, H, W):\n",
    "        \"\"\"\n",
    "        interpolate(up sample) & normalize\n",
    "        https://pytorch.org/docs/stable/nn.functional.html#interpolate\n",
    "        \"\"\"\n",
    "        gradcam = F.interpolate(gradcam, size=(H, W), mode=\"bilinear\", align_corners=False)\n",
    "        gradcam = self.normalization(gradcam)\n",
    "        return gradcam\n",
    "    \n",
    "    def normalization(self, tensor):\n",
    "        B, C, H, W = tensor.size()\n",
    "        tensor = tensor.view(B, -1)\n",
    "        t_min = tensor.min(dim=1, keepdim=True)[0]\n",
    "        t_max = tensor.max(dim=1, keepdim=True)[0]\n",
    "        t_mean = tensor.mean(dim=1, keepdim=True)\n",
    "        t_std = tensor.std(dim=1, keepdim=True)\n",
    "        if self.norm_mode == 1:\n",
    "            tensor -= t_min\n",
    "            tensor /= (t_max - t_min + 1e-10)\n",
    "        elif self.norm_mode == 2:\n",
    "            tensor -= t_min\n",
    "            tensor *= 2\n",
    "            tensor /= (t_max - t_min + 1e-10)\n",
    "        elif self.norm_mode == 3:\n",
    "            tensor -= t_mean\n",
    "            tensor /= t_std\n",
    "        return tensor.view(B, C, H, W)\n",
    "        \n",
    "    def get_attribution(self, x, targets):\n",
    "        *_, H, W = x.size()\n",
    "        self.model.zero_grad()\n",
    "        \n",
    "        output = self.model(x)\n",
    "        grad = self._one_hot(targets, module_name=\"fc\")\n",
    "        output.backward(grad)\n",
    "        \n",
    "        gradcam = self.cal_gradcam()\n",
    "        gradcam = self.post_processing(gradcam, H, W)\n",
    "        \n",
    "        return gradcam.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gradcam_model = GradCAM(model)\n",
    "x = torch.randn(1, 1, 28, 28)\n",
    "targets = torch.LongTensor([2])\n",
    "gradcam = gradcam_model.get_attribution(x, targets)\n",
    "plt.imshow(gradcam.squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GuidedBackprop(XaiModel):\n",
    "    \"\"\"GuidedBackprop\"\"\"\n",
    "    def __init__(self, model):\n",
    "        super(GuidedBackprop, self).__init__(model)\n",
    "        self.register_guided_hooks(self.model.convs)\n",
    "    \n",
    "    def reset_f_outputs(self):\n",
    "        self.f_outputs = []\n",
    "    \n",
    "    def register_guided_hooks(self, layers):\n",
    "        self.relu_f_hooks = []\n",
    "        self.relu_b_hooks = []\n",
    "        self.reset_f_outputs()\n",
    "        for layer in layers:\n",
    "            layer_name = type(layer).__name__\n",
    "            if layer_name.lower() == \"relu\":\n",
    "                f_hook = XaiHook(layer)\n",
    "                b_hook = XaiHook(layer)\n",
    "                self.relu_f_hooks.append(f_hook)\n",
    "                self.relu_b_hooks.append(b_hook)\n",
    "                \n",
    "        def guided_forward(m, i, o):\n",
    "            self.f_outputs.append(o.data)  \n",
    "            \n",
    "        def guided_backward(m, i, o):\n",
    "            deconv_grad = o[0].clamp(min=0)  # o: backward input\n",
    "            forward_output = self.f_outputs.pop(-1)\n",
    "            forward_mask = forward_output.ne(0.0).type_as(forward_output)\n",
    "            grad_in = deconv_grad * forward_mask\n",
    "            return (grad_in, )\n",
    "        \n",
    "        # register forward hooks\n",
    "        self._register_forward(self.relu_f_hooks, hook_fn=guided_forward)\n",
    "        self._register_backward(self.relu_b_hooks, hook_fn=guided_backward)\n",
    "        \n",
    "    def get_attribution(self, x, targets):\n",
    "        x.requires_grad_(True)\n",
    "        output = self.model(x)\n",
    "        grad = self._one_hot(targets, module_name=\"fc\")\n",
    "        output.backward(grad)\n",
    "        x_grad = x.grad.data.clone()\n",
    "        x.requires_grad_(False)\n",
    "        return x_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAXxklEQVR4nO2de5CcVZnGn7d7eu6Ty2SSEEhisiEI6Gp0B7CIuqirArsa3FqRaLlYZRndlQVd/1gvWyVV8gdSKmWVl9qwUEYXcalVFmqlxCzrim4BZoKRBAImhFyGDJnck7n27d0/ptkdYc5zxu6Z7inP86ua6pl++3zf2+f7nu/r6eec95i7Qwjxh0+m0QkIIeqDxC5EIkjsQiSCxC5EIkjsQiRCUz13lu3o8NzC7nru8v+JmQ5WfXOrcdtRatj+bKcmAjSo4wsnT6A0PDzl1msSu5ldCeDrALIA/tndb2Wvzy3sxvK/+3T4BbPYQZkCj5ebedzJvmPb9iyPx953psDfuDeFN1COHOFMkce91s9+s+jsRi+yBHY8a932xA4iYXZOxM7zcjjU/43bg7GqD6WZZQF8E8BVAC4GsNHMLq52e0KI2aWW6/alAPa6+z53zwP4AYANM5OWEGKmqUXs5wE4NOnv/spzv4OZbTKzPjPrKw0P17A7IUQt1CL2qf6zeMV/Ku6+2d173b0329FRw+6EELVQi9j7AayY9PdyAIdrS0cIMVvUIvZtANaa2WozawZwHYAHZiYtIcRMU7X15u5FM7sBwEOYsN7ucvenog2ZrRCxK6xEmkbsrZgFZRELil0WjVghAFBq42+s+RS/5ha6ePumqW1VAECZ2HJA3FqL9YvH+pUdsxraTqc9s6hilCPnU8wdi/UbO2ei52qVFnRNPru7PwjgwVq2IYSoDxouK0QiSOxCJILELkQiSOxCJILELkQiSOxCJEJd57NHiV16iO9abuZ+cnY0NqeRh4udYWPUirxx2xH+xkaXckO43MbjmULYFM7kadN4n0fiMZ/eW8Kxci5yzMZrKDIA8LERNU5Ljo4/qOE2GpteGxvXEUJ3diESQWIXIhEkdiESQWIXIhEkdiESQWIXIhHqb70R2yBmKZRz4VjuDL9uxaZL5hfwnTefjJWIDTO8mvs0rYf5YSjluQWV7yZvLuJetR+I7DsyPbcpkhtrH7PWsmOxOA3TqaKxacO5M3zfMXssP5+/oFr7DKje1tOdXYhEkNiFSASJXYhEkNiFSASJXYhEkNiFSASJXYhEqLvPzvzJmH+YIXZyzA+O+ezlVt6+nA/HFz7Dt310FffZm8b4Yeg8RMM4fUF4DEBsquZ4Dzd8m1bwJbuatnXReOvxsF89fC7v80IXz63QERlEkCEef2TKc35hZNpx5HzxHG/f1h8eNFJsn52lb3VnFyIRJHYhEkFiFyIRJHYhEkFiFyIRJHYhEkFiFyIR6uqzu/E56bHyvKWWGnzTxdxon/8U74pCZzhWznJfdO3yQRrvf2YljZ+6kIZRXBDuuCX/w9/X4BW800vH22g8vzziJ78Yvp+wpaYBIDfI40Mr+b7ZmI78Ml5Lun1vM40XO/gxzxT5AAfWPrqMdmTMSIiaxG5m+wGcxURF96K799ayPSHE7DETd/a3ufuxGdiOEGIW0f/sQiRCrWJ3AD81s+1mtmmqF5jZJjPrM7O+8hAfZy2EmD1q/Ri/3t0Pm9kSAFvN7Bl3f2TyC9x9M4DNANCyYsXsjPAXQkSp6c7u7ocrj4MA7gNw6UwkJYSYeaoWu5l1mFnXS78DeBeAXTOVmBBiZqnlY/xSAPeZ2Uvb+b67/4Q1MAcyxN6Mzb1m8dh89vaD/K2efh33XRc9Fm7/9hsfpW1/suVyGm+KTMvGqdiS0OHBC6fWRub5D/NOX7iL3w+K7Ty3118bvv4/+vPX0LZjyyK1/I9HvOzzR4Oxeb/i4wdGz+H9VpwX8fgLvF/KneHxDS2HyWAUAGU+BCBI1WJ3930AXl9teyFEfZH1JkQiSOxCJILELkQiSOxCJILELkQi1L2UtBNHgsUAvsRvbFpgKVL618b5BoZeFY7du+0SvvML+TTSmC1YmMdzH+kJ24YXrTlM2+7edy6Nl5u4vXXpdb+h8e3feV0wVnrTOG3r43zf5WZ+zFp3hu21kWWR0uFkOjUAeGTN5nn7eO75rrB/FrORUeU4VN3ZhUgEiV2IRJDYhUgEiV2IRJDYhUgEiV2IRJDYhUiE+paSBvfDM5FS0tmxsM8+ei5vnDsdeavz+BTX3P7WYKxpmE9J7H6W59b/Tl4buPf1e2n8iYMrgrHxLy2jbTPv4f3ScppP5fz15rCPDgBnLgqbwk2HW2jbmzb8B41/63vvofEPfvDhYOzue95B27avP07j+f/sofHxbhrG2Mo8CfJ7cPMJ4uETD153diESQWIXIhEkdiESQWIXIhEkdiESQWIXIhEkdiESoa4+uwHIEEu5HMkmR6zJ7Ai/buW7uV/csSvsowPA8GqSeGQJ3Qv+/Hka7/z4AhrfdtMaGmdli/dt5O+7vfssjRd2z6PxD934EI3/2y3vCsaOvjdc6hkAvvLou2l8zWNjNP6jY28PxjILaVN0tvC59id4c+6jA8gNhsdmxGovsGXPWU0I3dmFSASJXYhEkNiFSASJXYhEkNiFSASJXYhEkNiFSIQ5VTe+3Mz9xUJnONZ8gl+35h3gfnP+Wj5/uTUfNjdzv+Be9KEd59P4q+/cTeMXXL6Hxg/eHF4SungB94vHn++i8ZbI7eCOe6+k8eIbw8d04UN82eTjf8Z99J5bDvD2378wGBtdws+H/fuW0HhbBw1j/g6+rvI48fkLC/jADVabgZWzj97ZzewuMxs0s12Tnus2s61mtqfyGBmiIIRoNNP5GP8dAC+/fH8WwMPuvhbAw5W/hRBzmKjY3f0RvHJ04AYAWyq/bwFwzQznJYSYYar9gm6puw8AQOUx+A+OmW0ysz4z6ysND1e5OyFErcz6t/Huvtnde929N9sR+VZDCDFrVCv2I2a2DAAqj4Mzl5IQYjaoVuwPALi+8vv1AO6fmXSEELNF1Gc3s3sAXAGgx8z6AXwRwK0A7jWzjwI4COD909mZG+Bkj6wuPADkF4X9x5ZjfD3sI5dzX/X827jnu/8vwvH8pXxedvEpvu3uZv5dxrHe19J4iYxP6Hi0nbbd8blv0fgbbvlbGs8N0TD+8UP3BmN3X3IZbdv0TytpfPt7eXzVk+Hj0nKa16wfXczXAhjnJQgwvJyPGSm1h8/H1gEuyxJbO55IKCp2d98YCPEq+0KIOYWGywqRCBK7EIkgsQuRCBK7EIkgsQuRCPUtJe2AEQcsd4Zbb54N22tsKWgAaFsyQuMvXs6nqTavPR3eN5u3C2Csh9s8Wx+4hMbHb+RTPTt2hfe/8Le8pPFrH/sQjY+9mfdb+Th/b7c+HS4HnX96Pm1buJpPz138E25p7t0Ytmp7+vgxG10cmW7dw5fhtnF+QjKruNTG9w3uIgfRnV2IRJDYhUgEiV2IRJDYhUgEiV2IRJDYhUgEiV2IRKh7KWkQC3EsUt63hZSLHlscWTe5xK9rxmfIYmQwXGVn/m7ejbm3n+T7/i9enHf1LWGPHwCOrg973Sf+hk+fPffLvOTxvhu4H906yDtu8f1hL/zFy/i2W3bwZbSP9vJjfss7fhiMfeMXfFZ2doyfL6Vh/r69iXvl46vDYyeaD/CxCyXSLVqyWQghsQuRChK7EIkgsQuRCBK7EIkgsQuRCBK7EIlQf5+dYEXuu7J5vC3Hue+ZL/OSyp0nuC9abgl31dAK3rZrK/fRR//0LI0fal1K48OvCXu2ly8ZoG0f/UB4WWMAaHmG3w9GVxZo/PlV4WO6/MfcJ3/hGr7trie4D3/btz8QjC3p5+W/T/0ln6/e+gRf6rrMK1EDZD57oZOfT1lS3oDVi9CdXYhEkNiFSASJXYhEkNiFSASJXYhEkNiFSASJXYhEmFM+e4ZbmxjvCZuImQL36Oft5de1k+t5bXY2D7/tGe73nr6Y+8mtv+Ge7Zc+9l0a/8rnwrXfn3zVxbTt+bc/TuNtP+uh8VO38WWTX3hL2HA+/FbuJ/s4HzsxupS3L3aFz5fiW3g9fZT5+VKMeOFNQ5HlxxeG22f48AKU2sNt2foJ0Tu7md1lZoNmtmvSczeb2QtmtqPyc3VsO0KIxjKdj/HfAXDlFM/f7u7rKj8PzmxaQoiZJip2d38EwIk65CKEmEVq+YLuBjN7svIxPzj428w2mVmfmfWVhnk9NCHE7FGt2L8NYA2AdQAGAHw19EJ33+zuve7em+0IF20UQswuVYnd3Y+4e8ndywDuAHDpzKYlhJhpqhK7mS2b9Of7AOwKvVYIMTeI+uxmdg+AKwD0mFk/gC8CuMLM1mHCfd4P4OPT2psDRrz0TGQ+e7GD+KYtvOZ8fl7krZ7k9dOzo+HcRtZyz7b1IN92vpvn/oW7/prGxzaE52bbIK9B/uJNl9H4+BE+137BQu6FlzrD762ZrAMAAIVFfOBFYQn3ursfD3v8pwp8bEP7AM9t5HV8PnzXz/nYi5GV4bEXuZO8TzP58LlopEuiYnf3jVM8fWesnRBibqHhskIkgsQuRCJI7EIkgsQuRCJI7EIkQt2nuFo5bBuUc9xK6egPWxJDq7hN45ElmdsPR6Y0doRza32aW2sj67hNUy7wfa/4Fz799rk/DltM7f1822/a+Gsa/++H1tF40xi3DZeuORaMHSktpm19hJ+ezUd5/MwV4X7PNfFpxyPOR3uWI7mNLOE2coYsCW2R1cczJbJtIiHd2YVIBIldiESQ2IVIBIldiESQ2IVIBIldiESQ2IVIhLr67G5AqTVsBLLpeQAwTsrvLn6cG+lH1/P6vIu28a44fmF4Gmt+iLfN7efTHfM93Fh99mPc811zR3iMwfAy7oP/4uAaGs+95gyNHy/Op/GxA4uCsabFfPzA2mWDNH5g/yq+78Fwv2fOch+8vIyfL53P8LEVkRm08CZSDjrHcysQDdVUSloI8YeBxC5EIkjsQiSCxC5EIkjsQiSCxC5EIkjsQiRCXX128/hytLQ9sYxP8pWJkT0dmX98Dvc2kQ9fF7ue4x5/zHNd/GikHPNfHafxg+8Oe9nFc3iZ6wu+zN/3no2dNL6gNzxfHQCWfivsw7/wtjbadv/Tq2h8NFLCO3s8PM8/xryd3EcvtvP2rOw5wMtBR4abIDsejjGN6M4uRCJI7EIkgsQuRCJI7EIkgsQuRCJI7EIkgsQuRCLUfT57mVifGW6bRmu/M8qt3Pcca4747GT+8VgPd0bZcs8AMLKBzxkvbe+h8QWXHA3GWjcvpG333MhPgWxuhMYvWsTnnP96XTj3f7/2q7Ttpzd+gsb3LuF1Aua9+kQwZj/upm1jPnpsvEimwI8588OZRgBeE6Km+exmtsLMfmZmu83sKTO7qfJ8t5ltNbM9lUd+VgkhGsp0PsYXAXzG3S8C8CYAnzSziwF8FsDD7r4WwMOVv4UQc5So2N19wN2fqPx+FsBuAOcB2ABgS+VlWwBcM1tJCiFq5/f6gs7MVgF4A4DHASx19wFg4oIAYEmgzSYz6zOzvvLwcG3ZCiGqZtpiN7NOAD8E8Cl3598oTcLdN7t7r7v3Zjp44UQhxOwxLbGbWQ4TQr/b3X9UefqImS2rxJcB4F/LCiEaStR6MzMDcCeA3e7+tUmhBwBcD+DWyuP909ojc6ki7hdbNrn5JL9ueTZihRR5vO1AeMrjyLnc1ms9Filb/Bgvx1xYzK29UzuJNXcdt86yz3OP6dxf8qWwi1/g/d5MPgN+4u8/RdsevYpv28oRy/O+sL127C3cO7Mh7vN6M9+3jfPc2RTXJr7CN8qk1DQrxz4dn309gA8D2GlmOyrPfR4TIr/XzD4K4CCA909jW0KIBhEVu7v/EuF77jtmNh0hxGyh4bJCJILELkQiSOxCJILELkQiSOxCJEJ9S0mDW+nFTu5dtg2Er00jF/Plf1v28emQMcaWhHPLneXXzKGV3If3Hj63d/6veO5nzg9v38f5IfZuvlz0oQ9yn/3I4fNovLA6nNvwct5v5ZiXzVPHscvCL2jtIvWYAZQP8xLa7QN87MTQSp577ky4fbGLt2VRFtOdXYhEkNiFSASJXYhEkNiFSASJXYhEkNiFSASJXYhEqKvPHqNpiHuXBeI/xnx0tswtAOTnc2+zsDDsNxfm8bxzZ/jc6OxzPPfxSN1eVqq6FKlL3PEiv97n5/PcV/3rSRr/7UfCscyaIdp2wY+51z20gvf7/O3h2GgPX0f7zJ/wcRunF0TqPfOhFciQJcAttqw52TXrEd3ZhUgEiV2IRJDYhUgEiV2IRJDYhUgEiV2IRJDYhUiEuvvssTnIDOazdxyKLIt8Hjc+c2f4da/lxbC5GXtP4+dzz7bpWe6zl9r4GAC2fHBhEU9ubBHvN7Y8MAAcuoovfVyeH56r789yH/3UhTSMUhs/pidz4WNaauHvq+mFFhovR9rHlulm9d1jSzZXi+7sQiSCxC5EIkjsQiSCxC5EIkjsQiSCxC5EIkjsQiTCdNZnXwHguwDOwcQs3c3u/nUzuxnAxwAcrbz08+7+YGx7Ti4vzqdOo2kk7F2OnsM910yB+57FDt6erd/OfG4AyA7U5tkW2yP100nqrf3ctC3Mi/QbWUccAEptNIxWsq79+OLIAIUuXrMep/l7yy8Mb79tgJ9sbEwHAGTHIv3CDzky5K3FdGCRbgkxnUE1RQCfcfcnzKwLwHYz21qJ3e7uX6lu10KIejKd9dkHAAxUfj9rZrsB8GVAhBBzjt/rf3YzWwXgDQAerzx1g5k9aWZ3mdmUxZPMbJOZ9ZlZX2l4uKZkhRDVM22xm1kngB8C+JS7nwHwbQBrAKzDxJ3/q1O1c/fN7t7r7r3Zjo4ZSFkIUQ3TEruZ5TAh9Lvd/UcA4O5H3L3k7mUAdwC4dPbSFELUSlTsZmYA7gSw292/Nun5ZZNe9j4Au2Y+PSHETDGdb+PXA/gwgJ1mtqPy3OcBbDSzdZhYJXY/gI9PZ4fMJmIxgNt2MYsodlmLTeXMliLbJzRFpjtGrTUe5qWkI9Njae1h8KWFAaAwnx+0co6U/z7OPabSED9oMQuqMI9sO9YvEWL2WJavwk3P5ZgOqmU638b/ElOfElFPXQgxd9AIOiESQWIXIhEkdiESQWIXIhEkdiESQWIXIhHqXkqa+YvxxrPXNneWJ1YKz9SMe/hN1U9RBQCUudftNRzF6BTWyPgDNvUXAHJkKmgx4nXHxicUOnj75tPh9oXO2vYdtcIj4xecxGPjKqpFd3YhEkFiFyIRJHYhEkFiFyIRJHYhEkFiFyIRJHYhEsHcZ8nUm2pnZkcBHJj0VA+AY3VL4PdjruY2V/MClFu1zGRur3L3xVMF6ir2V+zcrM/dexuWAGGu5jZX8wKUW7XUKzd9jBciESR2IRKh0WLf3OD9M+ZqbnM1L0C5VUtdcmvo/+xCiPrR6Du7EKJOSOxCJEJDxG5mV5rZs2a218w+24gcQpjZfjPbaWY7zKyvwbncZWaDZrZr0nPdZrbVzPZUHqdcY69Bud1sZi9U+m6HmV3doNxWmNnPzGy3mT1lZjdVnm9o35G86tJvdf+f3cyyAH4L4J0A+gFsA7DR3Z+uayIBzGw/gF53b/gADDN7K4AhAN9199dWnrsNwAl3v7VyoVzo7v8wR3K7GcBQo5fxrqxWtGzyMuMArgHwETSw70he16IO/daIO/ulAPa6+z53zwP4AYANDchjzuPujwA48bKnNwDYUvl9CyZOlroTyG1O4O4D7v5E5fezAF5aZryhfUfyqguNEPt5AA5N+rsfc2u9dwfwUzPbbmabGp3MFCx19wFg4uQBsKTB+byc6DLe9eRly4zPmb6rZvnzWmmE2KeqvjWX/L/17v5GAFcB+GTl46qYHtNaxrteTLHM+Jyg2uXPa6URYu8HsGLS38sBHG5AHlPi7ocrj4MA7sPcW4r6yEsr6FYeBxucz/8xl5bxnmqZccyBvmvk8ueNEPs2AGvNbLWZNQO4DsADDcjjFZhZR+WLE5hZB4B3Ye4tRf0AgOsrv18P4P4G5vI7zJVlvEPLjKPBfdfw5c/dve4/AK7GxDfyzwH4QiNyCOT1RwB+U/l5qtG5AbgHEx/rCpj4RPRRAIsAPAxgT+Wxew7l9j0AOwE8iQlhLWtQbm/GxL+GTwLYUfm5utF9R/KqS79puKwQiaARdEIkgsQuRCJI7EIkgsQuRCJI7EIkgsQuRCJI7EIkwv8CFt5Tralb448AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "guided_model = GuidedBackprop(model)\n",
    "grad = guided_model.get_attribution(x, targets)\n",
    "plt.imshow(grad.squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaGrad(XaiModel):\n",
    "    \"\"\"VanillaGrad\"\"\"\n",
    "    def __init__(self, model):\n",
    "        super(VanillaGrad, self).__init__(model)\n",
    "        \n",
    "    def get_attribution(self, x, target):\n",
    "        \"\"\"vanilla gradient\"\"\"\n",
    "        x.requires_grad_(requires_grad=True)\n",
    "        self.model.zero_grad()\n",
    "        output = self.model(x)\n",
    "        grad = self._one_hot(targets, module_name=\"fc\")\n",
    "        output.backward(grad)\n",
    "        x_grad = x.grad.data.clone()\n",
    "        x.requires_grad_(requires_grad=False)\n",
    "        return x_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vanillagrad = VanillaGrad(model)\n",
    "grad = vanillagrad.get_attribution(x, targets)\n",
    "plt.imshow(grad.squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradInput(XaiModel):\n",
    "    \"\"\"GradInput\"\"\"\n",
    "    def __init__(self, model):\n",
    "        super(GradInput, self).__init__(model)\n",
    "        \n",
    "    def get_attribution(self, x, target):\n",
    "        \"\"\"vanilla gradient*input\"\"\"\n",
    "        x.requires_grad_(requires_grad=True)\n",
    "        self.model.zero_grad()\n",
    "        output = self.model(x)\n",
    "        grad = self._one_hot(targets, module_name=\"fc\")\n",
    "        output.backward(grad)\n",
    "        x_grad = x.grad.data.clone()\n",
    "        x.requires_grad_(requires_grad=False)\n",
    "        \n",
    "        return x_grad * x.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gradinput = GradInput(model)\n",
    "grad = gradinput.get_attribution(x, targets)\n",
    "plt.imshow(grad.squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeconvNet(XaiModel):\n",
    "    \"\"\"DeconvNet\"\"\"\n",
    "    def __init__(self, model, module_name=\"convs\"):\n",
    "        super(DeconvNet, self).__init__(model)\n",
    "        layer_names = [\"conv2d\", \"maxpool2d\"]\n",
    "        self.module_name = module_name\n",
    "        self.deconvs_indices = self.find_idxes(module_name, layer_names)\n",
    "        self.layers = self.make_layers(module_name)\n",
    "        self.init_weights(module_name, layer_name=\"conv2d\")\n",
    "        \n",
    "    def find_idxes(self, module_name, layer_names):\n",
    "        \"\"\"\n",
    "        args:\n",
    "        - module_name\n",
    "        - layer_names: \n",
    "        \n",
    "        return:\n",
    "        get `deconvs_indices` for the `module_name`, \n",
    "        - key: decovnet layer name \n",
    "        - values: indices dict match to {convnet:decovnet}\n",
    "        \"\"\"\n",
    "        convs_indices = self._find_target_layer_idx(module_name, layer_names)\n",
    "        last_layer_num = len(self.model._modules[module_name]) - 1\n",
    "        deconvs_indices = defaultdict(dict)\n",
    "        \n",
    "        for l_name in layer_names:\n",
    "            idxes = (last_layer_num - torch.LongTensor(convs_indices[l_name])).tolist()\n",
    "            deconvs_indices[l_name] = dict(zip(convs_indices[l_name], idxes))\n",
    "            if l_name == \"conv2d\":\n",
    "                deconvs_indices[l_name+\"-bias\"] = dict(zip(\n",
    "                    convs_indices[l_name], idxes[1:]+[None]))\n",
    "            \n",
    "        return deconvs_indices\n",
    "    \n",
    "    def make_layers(self, module_name):\n",
    "        \"\"\"\n",
    "        maxunpool > relu > conv \n",
    "        \"\"\"\n",
    "        layers = []\n",
    "        modules = self.model._modules[module_name]\n",
    "        for layer in modules:\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                temp_layer = nn.ConvTranspose2d(layer.out_channels,\n",
    "                                                layer.in_channels,\n",
    "                                                layer.kernel_size, \n",
    "                                                layer.stride, \n",
    "                                                layer.padding,\n",
    "                                                layer.output_padding,\n",
    "                                                layer.groups, \n",
    "                                                False,  # bias\n",
    "                                                layer.dilation,\n",
    "                                                layer.padding_mode)\n",
    "                layers.append(temp_layer)\n",
    "            elif isinstance(layer, nn.MaxPool2d):\n",
    "                temp_layer = nn.MaxUnpool2d(layer.kernel_size,\n",
    "                                            layer.stride,\n",
    "                                            layer.padding)\n",
    "                layers.append(temp_layer)\n",
    "            else:\n",
    "                layers.append(layer)\n",
    "        return nn.Sequential(*reversed(layers))\n",
    "    \n",
    "    def init_weights(self, module_name, layer_name):\n",
    "        convs = self.model._modules[module_name]\n",
    "        conv_indices = self.deconvs_indices[layer_name]\n",
    "        conv_bias_indices = self.deconvs_indices[layer_name+\"-bias\"]\n",
    "        for i, layer in enumerate(convs):\n",
    "            if type(layer).__name__.lower() == layer_name:\n",
    "                # ex: 3 conv layers (conv, relu, maxpool)\n",
    "                # 'conv2d': {0: 8, 3: 5, 6: 2}\n",
    "                # 'conv2d-bias': {0: 5, 3: 2, 6: None}\n",
    "                \n",
    "                deconv_idx = conv_indices.get(i)\n",
    "                weight = convs[i].weight.data\n",
    "                self.layers[deconv_idx].weight.data = weight\n",
    "                \n",
    "                deconv_bias_idx = conv_bias_indices.get(i)\n",
    "                if deconv_bias_idx is not None:\n",
    "                    bias = convs[i].bias\n",
    "                    self.layers[deconv_bias_idx].bias = bias\n",
    "                \n",
    "                            \n",
    "    def get_attribution(self, x, targets):\n",
    "        unpool_locations = self.deconvs_indices[\"maxpool2d\"]\n",
    "        unpool_locations = {v: k for k, v in unpool_locations.items()}\n",
    "        convs = self.model._modules[self.module_name]\n",
    "\n",
    "        switches = OrderedDict()\n",
    "        self._reset_maps()\n",
    "        self._return_indices(convs, on=True)\n",
    "        for i, layer in enumerate(convs):\n",
    "            if isinstance(layer, nn.MaxPool2d):\n",
    "                x, switch = layer(x)\n",
    "                switches[i] = switch\n",
    "            else:\n",
    "                x = layer(x)\n",
    "                \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            if isinstance(layer, nn.MaxUnpool2d):\n",
    "                j = unpool_locations[i]\n",
    "                x = layer(x, switches[j])\n",
    "            elif isinstance(layer, nn.ConvTranspose2d):\n",
    "                x = layer(x)\n",
    "                layer_name = type(layer).__name__.lower() + f\"-{i}\"\n",
    "                self._save_maps(layer_name, x.data)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        self._return_indices(convs, on=False)\n",
    "        x_ret = x.clone().detach().data\n",
    "        return x_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "deconvnet = DeconvNet(model)\n",
    "x_ret = deconvnet.get_attribution(x, targets)\n",
    "plt.imshow(x_ret.squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRP(XaiModel):\n",
    "    \"\"\"LRP\"\"\"\n",
    "    def __init__(self, model):\n",
    "        super(LRP, self).__init__(model)\n",
    "        \n",
    "    def \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = relLinear(linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([-0.1114,  1.4844, -1.3424,  0.4873]),)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.8536,  0.0637, -0.1043, -0.2172,  0.8663], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a(torch.randn(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class relLinear(XaiHook):\n",
    "    def __init__(self, module, use_rho=False):\n",
    "        \"\"\"\n",
    "        forward\n",
    "        > input: (B, *, in_f)\n",
    "        > output: (B, *, out_f)\n",
    "        \"\"\"\n",
    "        super(relLinear, self).__init__(module)\n",
    "        self.use_rho = use_rho\n",
    "        self.register_hook(backward=False, hook_fn=self.f_hook)\n",
    "        self.register_hook(backward=True, hook_fn=self.b_hook)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        return self.module(x)\n",
    "    \n",
    "    def f_hook(self, m, i, o):\n",
    "        \"\"\"\n",
    "        forward hook\n",
    "        i: (input,)\n",
    "        o: output\n",
    "        \"\"\"\n",
    "        self.input = i[0].clone().data\n",
    "        self.output = o.clone().data\n",
    "    \n",
    "    def b_hook(self, m, i, o):\n",
    "        \"\"\"\n",
    "        backward hook\n",
    "        i: (bias, input, weight) -> backward output\n",
    "        o: (output,) -> backward input\n",
    "        \n",
    "        ### implementation method 1\n",
    "        [Step 1]: (B, in_f, 1) * (1, in_f, out_f) = (B, in_f, out_f)\n",
    "        [Step 2]: (B, 1, out_f), do not multiply `torch.sign(self.output.unsqueeze(1))` \n",
    "                  that returns `nan` in tensor\n",
    "        [Step 3]: divide by s\n",
    "        [Step 4]: (B, in_f, out_f) x (B, out_f, 1) = (B, in_f)\n",
    "        ```\n",
    "        # Step 1\n",
    "        z = self.input.unsqueeze(-1) * self.rho(self.weight).transpose(0, 1).unsqueeze(0)\n",
    "        # Step 2\n",
    "        s = self.output.unsqueeze(1) + eps * torch.sign(self.output.unsqueeze(1))  \n",
    "        # Step 3\n",
    "        weight = z / s\n",
    "        # Step 4\n",
    "        r_next = torch.bmm(weight, r.unsqueeze(-1)).squeeze()\n",
    "        ```\n",
    "        ### implemetation method 2\n",
    "        # Step 1: (B, out_f), do not multiply `torch.sign(self.output)` that returns `nan` in tensor\n",
    "        # Step 2: (B, out_f) / (B, out_f) = (B, out_f)\n",
    "        # Step 3: (B, in_f, out_f) * (B, out_f, 1) = (B, in_f)\n",
    "        # Step 4: (B, in_f) x (B, in_f) = (B, in_f)\n",
    "        ```\n",
    "        # Step 1\n",
    "        s = self.output + eps\n",
    "        # Step 2\n",
    "        e = r / s\n",
    "        # Step 3\n",
    "        c = torch.bmm(w.transpose(0, 1).expand(e.size(0), self.in_features, self.out_features), \n",
    "                      e.unsqueeze(-1)).squeeze(-1)\n",
    "        # Step 4\n",
    "        r_next = self.input * c\n",
    "        ```\n",
    "        \"\"\"\n",
    "        r = o[0]\n",
    "        eps = 1e-6\n",
    "        w = self.rho(self.module.weight).data\n",
    "        # Step 1\n",
    "        s = self.output + eps\n",
    "        # Step 2\n",
    "        e = r / s\n",
    "        # Step 3\n",
    "        c = torch.bmm(w.transpose(0, 1).expand(e.size(0), \n",
    "                                               self.module.in_features, \n",
    "                                               self.module.out_features), \n",
    "                      e.unsqueeze(-1)).squeeze(-1)\n",
    "        # Step 4\n",
    "        r_next = self.input * c\n",
    "        assert r_next.size(1) == self.module.in_features, \"size of `r_next` is not correct\"\n",
    "        return r_next\n",
    "        \n",
    "    def rho(self, w):\n",
    "        if self.use_rho:\n",
    "            return torch.clamp(w, min=0)\n",
    "        else:\n",
    "            return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = nn.Linear(4, 2)\n",
    "a = relLinear(linear)\n",
    "eps = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "a(torch.randn(1, 4)).backward(torch.FloatTensor([[1, 0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = a.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = a.rho(a.module.weight).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = a.output + eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = r / s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.bmm(w.transpose(0, 1).expand(e.size(0), \n",
    "                                       a.module.in_features, \n",
    "                                       a.module.out_features), \n",
    "              e.unsqueeze(-1)).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4486, -0.3609,  0.5477, -0.5088]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.9931,  0.4725,  0.0990, -0.9215])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class relReLU(XaiHook):\n",
    "    \"\"\"relReLU\"\"\"\n",
    "    def __init__(self, module):\n",
    "        super(relLinear, self).__init__(module)\n",
    "        self.register_hook(backward=True, hook_fn=self.b_hook)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        return self.module(x)\n",
    "    \n",
    "    def b_hook(self, m, i, o):\n",
    "        inp, _, bias = i\n",
    "        r = o\n",
    "        return (inp, r_next, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRP(nn.Module):\n",
    "    \"\"\"LRP\"\"\"\n",
    "    def __init__(self, model):\n",
    "        super(LRP, self).__init__()\n",
    "        # lrp\n",
    "        self.activation_func = model.activation_func\n",
    "        self.model_type = model.model_type\n",
    "        self.activation_type = model.activation_type\n",
    "        \n",
    "        self.layers = self.lrp_make_layers(model)\n",
    "        \n",
    "    def reset_activation_maps(self):\n",
    "        self.activation_maps = OrderedDict()\n",
    "\n",
    "    def lrp_make_layers(self, model):\n",
    "        layers = []\n",
    "        mapping_dict = {nn.Linear: relLinear, nn.Conv2d: relConv2d, nn.MaxPool2d: relMaxPool2d, \n",
    "                        nn.ReLU: relReLU}\n",
    "        for layer in model.layers:\n",
    "            if isinstance(layer, Reshape):\n",
    "                layers.append(layer)\n",
    "            else:\n",
    "                layers.append(mapping_dict[layer.__class__](layer))\n",
    "                \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        lrp method\n",
    "        must run forward first to save input and output at each layer\n",
    "        \"\"\"\n",
    "        self.reset_activation_maps()\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    def save_activation_maps(self, layer, typ, idx, x):\n",
    "        if isinstance(layer, typ):\n",
    "            layer_name = f\"({idx}) {str(layer).split('(')[0]}\"\n",
    "            self.activation_maps[layer_name] = x\n",
    "    \n",
    "    def get_attribution(self, x, target=None, store=False, use_rho=False):\n",
    "        \"\"\"\n",
    "        store: if True, save activation maps\n",
    "        \"\"\"\n",
    "        o = self.forward(x).detach()\n",
    "        r = o * torch.zeros_like(o).scatter(1, o.argmax(1, keepdim=True), 1)\n",
    "        for idx, layer in enumerate(self.layers[::-1]):\n",
    "            r = layer.relprop(r, use_rho)\n",
    "            if store:\n",
    "                self.save_activation_maps(layer, relConv2d, idx, r)\n",
    "        return r.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "class relReLU(nn.ReLU):\n",
    "    \"\"\"relReLU\"\"\"\n",
    "    def relprop(self, r, use_rho=False): \n",
    "        return r\n",
    "    \n",
    "    \n",
    "class relConv2d(nn.Conv2d):\n",
    "    \"\"\"relConv2d\"\"\"\n",
    "    def __init__(self, conv2d):\n",
    "        super(nn.Conv2d, self).__init__(conv2d.in_channels, \n",
    "                                        conv2d.out_channels, \n",
    "                                        conv2d.kernel_size, \n",
    "                                        conv2d.stride, \n",
    "                                        conv2d.padding,\n",
    "                                        conv2d.dilation,\n",
    "                                        conv2d.transposed,\n",
    "                                        conv2d.output_padding,\n",
    "                                        conv2d.groups, \n",
    "                                        None,  # init of bias\n",
    "                                        conv2d.padding_mode)\n",
    "        self.weight = conv2d.weight\n",
    "        self.bias = conv2d.bias\n",
    "        \n",
    "        self.input = None\n",
    "        self.output = None\n",
    "        self.register()\n",
    "        \n",
    "    def register(self):\n",
    "        self.register_forward_hook(self.hook_function)\n",
    "    \n",
    "    def hook_function(self, *x):\n",
    "        _, i, o = x\n",
    "        self.input = i[0].data\n",
    "        self.output = o.data\n",
    "    \n",
    "    def rho(self, w, use_rho):\n",
    "        if use_rho:\n",
    "            return torch.clamp(w, min=0)\n",
    "        else:\n",
    "            return w\n",
    "    \n",
    "    def cal_output_padding(self):\n",
    "        \"\"\"\n",
    "        calculate output_padding size\n",
    "        - size of height or width: (X_in + 2P - K) / S + 1 = X_out\n",
    "        - output_padding = X_in - ((X_out - 1) * S + K - 2P)\n",
    "\n",
    "        * what is output_padding?\n",
    "        from PyTorch Document:\n",
    "        https://pytorch.org/docs/stable/nn.html#convtranspose2d\n",
    "\n",
    "        The padding argument effectively adds `dilation * (kernel_size - 1) - padding` amount of zero padding to \n",
    "        both sizes of the input. This is set so that when a `Conv2d` and a `ConvTranspose2d` are initialized with \n",
    "        same parameters, they are inverses of each other in regard to the input and output shapes. \n",
    "        However, when `stride > 1`, `Conv2d` maps multiple input shapes to the same output shape. \n",
    "        `output_padding` is provided to resolve this ambiguity by effectively increasing \n",
    "        the calculated output shape on one side. Note that output_padding is only used to find output shape, \n",
    "        but does not actually add zero-padding to output.\n",
    "        \"\"\"\n",
    "        H_in, W_in = self.input.size()[2:]\n",
    "        H_out, W_out = self.output.size()[2:]\n",
    "        S_in, S_out = self.stride\n",
    "        K_in, K_out = self.kernel_size\n",
    "        P_in, P_out = self.padding\n",
    "        H_output_padding = H_in - ((H_out - 1)*S_in + K_in - 2*P_in)\n",
    "        W_output_padding = W_in - ((W_out - 1)*S_out + K_out - 2*P_out)\n",
    "        return (H_output_padding, W_output_padding)\n",
    "    \n",
    "    def gradprop(self, x):\n",
    "        \"\"\"\n",
    "        `ConvTransposed2d` can be seen as the gradient of `Conv2d` with respect to its input.\n",
    "        \"\"\"\n",
    "        output_padding = self.cal_output_padding()\n",
    "        c = torch.nn.functional.conv_transpose2d(x, weight=self.weight, stride=self.stride, \n",
    "                                                 padding=self.padding, output_padding=output_padding)\n",
    "        return c\n",
    "    \n",
    "    def relprop(self, r, use_rho=False):\n",
    "        \"\"\"\n",
    "        lrp method\n",
    "            > * must run after `self.forward`\n",
    "            > \n",
    "            > forward shape\n",
    "            > input: (B, C_in, H, W)\n",
    "            > output: (B, C_out, H_out, W_out)\n",
    "\n",
    "        - relprop shape\n",
    "        r = (l+1)-th layer: (B, C_out, H_out, W_out)\n",
    "        r_next = l-th layer: (B, C_in, H, W)\n",
    "        \n",
    "        if rho==True:\n",
    "        function rho(w) is applied\n",
    "        \"\"\"\n",
    "        eps = 1e-6\n",
    "        w = self.rho(self.weight, use_rho)\n",
    "        # Step 1: (B, C_out, H_out, W_out), do not multiply `torch.sign(self.output)` that returns `nan` in tensor\n",
    "        s = self.output + eps \n",
    "        # Step 2: (B, C_out, H_out, W_out) / (B, C_out, H_out, W_out) = (B, C_out, H_out, W_out)\n",
    "        e = r / s\n",
    "        # Step 3: (B, C_out, H_out, W_out) --> (B, C_in, H, W)\n",
    "        # same as `self.gradprop(s*e)` or `(s*e).backward(); c=self.input.grad`\n",
    "        c = self.gradprop(e)\n",
    "        # Step 4: (B, C_in, H, W) x (B, C_in, H, W) = (B, C_in, H, W)\n",
    "        r_next = self.input * c\n",
    "        return r_next\n",
    "    \n",
    "\n",
    "class relMaxPool2d(nn.MaxPool2d):\n",
    "    \"\"\"relMaxPool2d\"\"\"\n",
    "    def __init__(self, maxpool2d):\n",
    "        super(nn.MaxPool2d, self).__init__(maxpool2d.kernel_size,\n",
    "                                           maxpool2d.stride,\n",
    "                                           maxpool2d.padding,\n",
    "                                           maxpool2d.dilation,\n",
    "                                           maxpool2d.return_indices,\n",
    "                                           maxpool2d.ceil_mode)    \n",
    "        self.input = None\n",
    "        self.output = None\n",
    "        self.register()\n",
    "\n",
    "    def register(self):\n",
    "        self.register_forward_hook(self.hook_function)\n",
    "    \n",
    "    def hook_function(self, *x):\n",
    "        _, i, o = x\n",
    "        self.input = i[0].data\n",
    "        self.output = o[0].data\n",
    "        \n",
    "    def gradprop(self, x):\n",
    "        _, switches = torch.nn.functional.max_pool2d(self.input, self.kernel_size, self.stride, self.padding, \n",
    "                                                     self.dilation, self.ceil_mode, return_indices=True)\n",
    "        c = torch.nn.functional.max_unpool2d(x, switches, self.kernel_size, self.stride, self.padding)\n",
    "        return c\n",
    "    \n",
    "    def relprop(self, r, use_rho=False):\n",
    "        \"\"\"\n",
    "        lrp method\n",
    "            > * must run after `self.forward`\n",
    "            > \n",
    "            > forward shape\n",
    "            > input: (B, C, H, W)\n",
    "            > output: (B, C, H_out, W_out)\n",
    "\n",
    "        - relprop shape\n",
    "        r = (l+1)-th layer: (B, C, H_out, W_out)\n",
    "        r_next = l-th layer: (B, C, H, W)\n",
    "        \n",
    "        rho: no use\n",
    "        \"\"\"\n",
    "        eps = 1e-6\n",
    "        # Step 1: (B, C, H_out, W_out), do not multiply `torch.sign(self.output)` that returns `nan` in tensor\n",
    "        s = self.output + eps\n",
    "        # Step 2: (B, C, H_out, W_out) / (B, C, H_out, W_out) = (B, C, H_out, W_out)\n",
    "        e = r / s\n",
    "        # Step 3: (B, C, H_out, W_out) --> (B, C, H, W)\n",
    "        # same as `self.gradprop(s*e)` or `(s*e).backward(); c=self.input.grad`\n",
    "        c = self.gradprop(e)\n",
    "        # Step 4: (B, C, H, W) x (B, C, H, W) = (B, C_in, H, W)\n",
    "        r_next = self.input * c\n",
    "        return r_next"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
