{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchxai.base import XaiBase, XaiHook, XaiModel\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7289,  0.0000, -0.3110, -0.6438, -0.7430, -0.5807, -0.6187,\n",
       "          -0.4700, -0.3572, -0.6628],\n",
       "         [-0.7202, -0.4709, -0.3033, -0.5704, -0.6878, -0.5745, -0.1280,\n",
       "           0.0000, -0.1001, -0.7426],\n",
       "         [-0.5903, -0.5981, -0.4960, -0.2572, -0.4529,  0.0000, -0.2227,\n",
       "          -0.8297, -0.0141, -0.5203]],\n",
       "\n",
       "        [[-0.1942, -0.2035, -0.6686, -0.1076, -0.5407,  0.0000, -0.8057,\n",
       "          -0.9370, -0.3398, -0.1131],\n",
       "         [-0.9071, -0.5024, -0.6828, -0.5934, -0.0292, -0.2424, -0.9334,\n",
       "          -0.0755,  0.0000, -0.8552],\n",
       "         [-0.1788, -0.4843, -0.4293, -0.1438,  0.0000, -0.7191, -0.0985,\n",
       "          -0.0760, -0.5040, -0.6202]],\n",
       "\n",
       "        [[-0.7993, -0.7364, -0.3959, -0.7230, -0.8014,  0.0000, -0.1825,\n",
       "          -0.2260, -0.1536, -0.2798],\n",
       "         [-0.5706, -0.2290, -0.4174, -0.2329, -0.5421, -0.4341, -0.8639,\n",
       "          -0.5657, -0.3743,  0.0000],\n",
       "         [-0.3949, -0.4742, -0.1982, -0.6709, -0.3717,  0.0000, -0.1012,\n",
       "          -0.2595, -0.5961, -0.2550]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x - x.max(-1, keepdim=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9614, 0.6505, 0.6042, 0.4914, 0.3808, 0.3427, 0.3177, 0.2986,\n",
       "          0.2325, 0.2185],\n",
       "         [0.9679, 0.8678, 0.8399, 0.6646, 0.4970, 0.3975, 0.3934, 0.2801,\n",
       "          0.2477, 0.2253],\n",
       "         [0.8938, 0.8798, 0.6711, 0.6366, 0.4409, 0.3978, 0.3735, 0.3035,\n",
       "          0.2957, 0.0641]],\n",
       "\n",
       "        [[0.9646, 0.8570, 0.8515, 0.7704, 0.7611, 0.6248, 0.4239, 0.2961,\n",
       "          0.1589, 0.0276],\n",
       "         [0.9390, 0.9098, 0.8635, 0.6966, 0.4366, 0.3455, 0.2562, 0.0838,\n",
       "          0.0319, 0.0056],\n",
       "         [0.7907, 0.7147, 0.6921, 0.6468, 0.6119, 0.3613, 0.3064, 0.2866,\n",
       "          0.1704, 0.0716]],\n",
       "\n",
       "        [[0.9008, 0.7472, 0.7183, 0.6748, 0.6210, 0.5049, 0.1778, 0.1644,\n",
       "          0.1015, 0.0994],\n",
       "         [0.9872, 0.7582, 0.7542, 0.6129, 0.5697, 0.5531, 0.4450, 0.4215,\n",
       "          0.4166, 0.1233],\n",
       "         [0.9090, 0.8079, 0.7109, 0.6540, 0.6495, 0.5373, 0.5141, 0.4348,\n",
       "          0.3129, 0.2381]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlimpseSensor(nn.Module):\n",
    "    \"\"\"Glimpse Sensor\"\"\"\n",
    "    def __init__(self, g, k, s):\n",
    "        \"\"\"\n",
    "        retina and location encoding\n",
    "        ----\n",
    "        The retina encoding `ρ(x, l)` extracts `k` square \n",
    "        patches centered at location `l`, with the first patch \n",
    "        being `g_w` × `g_w` pixels in size, and each successive \n",
    "        patch having twice the width of the previous. \n",
    "        The k patches are then all resized to `g_w × g_w` \n",
    "        and concatenated. \n",
    "        Glimpse locations `l` were encoded \n",
    "        as real-valued (x, y) coordinates with \n",
    "        (0, 0) being the center of the image x and \n",
    "        (−1, −1) being the top left corner of x.\n",
    "        \n",
    "        args:\n",
    "        - g: size of first square patches\n",
    "        - k: number of patches\n",
    "        - s: scaling factor to control patches\n",
    "        \"\"\"\n",
    "        super(GlimpseSensor, self).__init__()\n",
    "        self.g = g\n",
    "        self.k = k\n",
    "        selk.s = s\n",
    "    \n",
    "    def extract_patch(self, x, l):\n",
    "        B, C, H, W = x.size()\n",
    "        \n",
    "    \n",
    "    def encode_coordinates(self, l):\n",
    "        \"\"\"\n",
    "        encode coordinates to (-1, 1) range\n",
    "        - center: (0, 0)\n",
    "        - topleft: (-1, -1)\n",
    "        \"\"\"\n",
    "        \n",
    "        return \n",
    "        \n",
    "    \n",
    "    def forward(self, x, l):\n",
    "        \"\"\"\n",
    "        args:\n",
    "        - x: current time step input data, (B, C, H, W)\n",
    "        - l: previous time step location, (B, 2)\n",
    "        \n",
    "        returns:\n",
    "        - rho: retina-like representation\n",
    "        \"\"\"\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
