{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchxai.base import XaiBase, XaiHook, XaiModel\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlimpseSensor(nn.Module):\n",
    "    \"\"\"Glimpse Sensor\"\"\"\n",
    "    def __init__(self, g, k, s):\n",
    "        \"\"\"\n",
    "        retina and location encoding\n",
    "        ----\n",
    "        The retina encoding `ρ(x, l)` extracts `k` square \n",
    "        patches centered at location `l`, with the first patch \n",
    "        being `g_w` × `g_w` pixels in size, and each successive \n",
    "        patch having twice the width of the previous. \n",
    "        The k patches are then all resized to `g_w × g_w` \n",
    "        and concatenated. \n",
    "        Glimpse locations `l` were encoded \n",
    "        as real-valued (x, y) coordinates with \n",
    "        (0, 0) being the center of the image x and \n",
    "        (−1, −1) being the top left corner of x.\n",
    "        \n",
    "        args:\n",
    "        - g: size of first square patches\n",
    "        - k: number of patches\n",
    "        - s: scaling factor to control patches\n",
    "        \"\"\"\n",
    "        super(GlimpseSensor, self).__init__()\n",
    "        self.g = g\n",
    "        self.k = k\n",
    "        selk.s = s\n",
    "    \n",
    "    def extract_patch(self, x, l):\n",
    "        B, C, H, W = x.size()\n",
    "        \n",
    "    \n",
    "    def encode_coordinates(self, l):\n",
    "        \"\"\"\n",
    "        encode coordinates to (-1, 1) range\n",
    "        - center: (0, 0)\n",
    "        - topleft: (-1, -1)\n",
    "        \"\"\"\n",
    "        \n",
    "        return \n",
    "        \n",
    "    \n",
    "    def forward(self, x, l):\n",
    "        \"\"\"\n",
    "        args:\n",
    "        - x: current time step input data, (B, C, H, W)\n",
    "        - l: previous time step location, (B, 2)\n",
    "        \n",
    "        returns:\n",
    "        - rho: retina-like representation\n",
    "        \"\"\"\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
